{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "30bb4cfa1ce14d8797783941027ee944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bafd6024ee934bfd9813907fc3138b54",
              "IPY_MODEL_0bf1aeb0033646839e365a65cfd30fd5",
              "IPY_MODEL_4d6fa08090a54dd19a9022063b684534"
            ],
            "layout": "IPY_MODEL_2de6ed0290694b309f48a3b130960c36"
          }
        },
        "bafd6024ee934bfd9813907fc3138b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c7a3ac820c140c8a40bc2d873eed4b2",
            "placeholder": "​",
            "style": "IPY_MODEL_53025ebce26a4bd5a674c17931808f33",
            "value": "vocab.json: 100%"
          }
        },
        "0bf1aeb0033646839e365a65cfd30fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e458124e561f4c0cb3b350836d07c7ba",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5be3349556004c86a0b6e037a92e5a9c",
            "value": 898823
          }
        },
        "4d6fa08090a54dd19a9022063b684534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2271a26b0bd74744a82629be6cf14598",
            "placeholder": "​",
            "style": "IPY_MODEL_910d801480384851a62bd6e34bd5339c",
            "value": " 899k/899k [00:00&lt;00:00, 8.94MB/s]"
          }
        },
        "2de6ed0290694b309f48a3b130960c36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c7a3ac820c140c8a40bc2d873eed4b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53025ebce26a4bd5a674c17931808f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e458124e561f4c0cb3b350836d07c7ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5be3349556004c86a0b6e037a92e5a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2271a26b0bd74744a82629be6cf14598": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "910d801480384851a62bd6e34bd5339c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe2a5dd0fb93407fb4c22515cdc04d1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_483735a71055407bb7f1a319af2d8a8c",
              "IPY_MODEL_e77f05f5db5740cf9c0448071c81e578",
              "IPY_MODEL_906d395ba6ae4c4194b81b052a753563"
            ],
            "layout": "IPY_MODEL_879a1d0f6cf044ba800bca85a35756d4"
          }
        },
        "483735a71055407bb7f1a319af2d8a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9e9e9522c5b4702968fccdacca0ef63",
            "placeholder": "​",
            "style": "IPY_MODEL_fbb233c1d060415aa8756901abd0e5be",
            "value": "merges.txt: 100%"
          }
        },
        "e77f05f5db5740cf9c0448071c81e578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1663ea97415a403fa0e1e624076391f1",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3372dd3ecd4445908184f89fd138c0b9",
            "value": 456318
          }
        },
        "906d395ba6ae4c4194b81b052a753563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65ce3d29f50b4c0f8a3d7bb417430ee5",
            "placeholder": "​",
            "style": "IPY_MODEL_c9a01b870633496b8340ce927ad45879",
            "value": " 456k/456k [00:00&lt;00:00, 15.2MB/s]"
          }
        },
        "879a1d0f6cf044ba800bca85a35756d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9e9e9522c5b4702968fccdacca0ef63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbb233c1d060415aa8756901abd0e5be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1663ea97415a403fa0e1e624076391f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3372dd3ecd4445908184f89fd138c0b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65ce3d29f50b4c0f8a3d7bb417430ee5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9a01b870633496b8340ce927ad45879": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fbf771fe0ca4ca2b6c75365690efec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9739689ac3274ccc94062955e1bd89bd",
              "IPY_MODEL_0bf41ef364b746afab39a613ff3e1066",
              "IPY_MODEL_d7ef5743f31842a5840cddaef89fdd38"
            ],
            "layout": "IPY_MODEL_540006618e2a4d389ff21bfcbb59c846"
          }
        },
        "9739689ac3274ccc94062955e1bd89bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e79956f596e48029edde89daac4c237",
            "placeholder": "​",
            "style": "IPY_MODEL_63ea829e0d2647b191e42b7138837f94",
            "value": "tokenizer.json: 100%"
          }
        },
        "0bf41ef364b746afab39a613ff3e1066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_265f6ac6ce2d4920b619354e3ad92739",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4615a0b3899c41588c372d0f3945f5f0",
            "value": 1355863
          }
        },
        "d7ef5743f31842a5840cddaef89fdd38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cba3b9612b5e43b9a3456da1f9460355",
            "placeholder": "​",
            "style": "IPY_MODEL_d6ed26c87acd46998fcd28e6d5ed7b3e",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 16.1MB/s]"
          }
        },
        "540006618e2a4d389ff21bfcbb59c846": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e79956f596e48029edde89daac4c237": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63ea829e0d2647b191e42b7138837f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "265f6ac6ce2d4920b619354e3ad92739": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4615a0b3899c41588c372d0f3945f5f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cba3b9612b5e43b9a3456da1f9460355": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6ed26c87acd46998fcd28e6d5ed7b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a88ff4cdd1c2439792bcf00783d4de85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5fd91342f2548b382a27870566ff42d",
              "IPY_MODEL_c7ba810bd4b64d2a8dfce9e65daac469",
              "IPY_MODEL_56c03f6a2c4e437ea1f0c254d16c22d9"
            ],
            "layout": "IPY_MODEL_1098cb43d7b14055920ea51d70ba2433"
          }
        },
        "b5fd91342f2548b382a27870566ff42d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7ef4ddcd4984e519e139acc96dee03c",
            "placeholder": "​",
            "style": "IPY_MODEL_12ea7f58175d4b37b983e7ccd05c8442",
            "value": "config.json: 100%"
          }
        },
        "c7ba810bd4b64d2a8dfce9e65daac469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_627e4cf597fb46d5a116f5b217503114",
            "max": 1585,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_588839d6693946feb92ba56305e79cb5",
            "value": 1585
          }
        },
        "56c03f6a2c4e437ea1f0c254d16c22d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e7f69c207394580af8d0bda72aafa69",
            "placeholder": "​",
            "style": "IPY_MODEL_a7e0649967ab4a4f80958b888f93c834",
            "value": " 1.58k/1.58k [00:00&lt;00:00, 26.8kB/s]"
          }
        },
        "1098cb43d7b14055920ea51d70ba2433": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7ef4ddcd4984e519e139acc96dee03c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12ea7f58175d4b37b983e7ccd05c8442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "627e4cf597fb46d5a116f5b217503114": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "588839d6693946feb92ba56305e79cb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e7f69c207394580af8d0bda72aafa69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7e0649967ab4a4f80958b888f93c834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3b4e44410714d19b0e912e6241dc4dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e161780e18d4cdc9502f6ae9740fa19",
              "IPY_MODEL_b2e2a2225b954aee810594c4a330cce8",
              "IPY_MODEL_d11bb6b8c00b4ef1954dfb7983796c51"
            ],
            "layout": "IPY_MODEL_38a5d01dbade4689a5308cdba26e3bf2"
          }
        },
        "7e161780e18d4cdc9502f6ae9740fa19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6f0524e946a415c981bf093f817743d",
            "placeholder": "​",
            "style": "IPY_MODEL_b97f71a5281d479681b81737e40e30c5",
            "value": "model.safetensors: 100%"
          }
        },
        "b2e2a2225b954aee810594c4a330cce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8ad0fa57b1b4d7296ebee67a8f9633b",
            "max": 1625222120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1ec9b03178e406ca1fc20daaabe0d78",
            "value": 1625222120
          }
        },
        "d11bb6b8c00b4ef1954dfb7983796c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcd6da10555a49a4a6952a0fdebc81ca",
            "placeholder": "​",
            "style": "IPY_MODEL_5289f8cfa86145fc8e9e1b980c4408df",
            "value": " 1.63G/1.63G [00:22&lt;00:00, 91.5MB/s]"
          }
        },
        "38a5d01dbade4689a5308cdba26e3bf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6f0524e946a415c981bf093f817743d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b97f71a5281d479681b81737e40e30c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8ad0fa57b1b4d7296ebee67a8f9633b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1ec9b03178e406ca1fc20daaabe0d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fcd6da10555a49a4a6952a0fdebc81ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5289f8cfa86145fc8e9e1b980c4408df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38a0711c26e74c7999b9867049d189d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2255004fe3694f749f4c28775d32ba91",
              "IPY_MODEL_9fbfe0d205ce43ad804553634e888c6f",
              "IPY_MODEL_be794a8caf4c458e904c1650a724cdaf"
            ],
            "layout": "IPY_MODEL_d968cb72c6264284be601444726587a8"
          }
        },
        "2255004fe3694f749f4c28775d32ba91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_799ddc0c7e324c4f87d6152cd88bed9a",
            "placeholder": "​",
            "style": "IPY_MODEL_b2b06e4f964a48a48822bc68ed17d41c",
            "value": "generation_config.json: 100%"
          }
        },
        "9fbfe0d205ce43ad804553634e888c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29567b88e30e4918b00163ef71e600b4",
            "max": 363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5162df791f9645e2ad986eb30a479cce",
            "value": 363
          }
        },
        "be794a8caf4c458e904c1650a724cdaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95b7be83949346ecb43826fa57120273",
            "placeholder": "​",
            "style": "IPY_MODEL_4db229147e204e499c5417e03352c713",
            "value": " 363/363 [00:00&lt;00:00, 12.3kB/s]"
          }
        },
        "d968cb72c6264284be601444726587a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "799ddc0c7e324c4f87d6152cd88bed9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2b06e4f964a48a48822bc68ed17d41c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29567b88e30e4918b00163ef71e600b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5162df791f9645e2ad986eb30a479cce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95b7be83949346ecb43826fa57120273": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4db229147e204e499c5417e03352c713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ehc5dKDm1HQa",
        "outputId": "0ed55d48-981f-4c67-c9bf-ef1c7bd0750e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Initialize the BART model and tokenizer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "30bb4cfa1ce14d8797783941027ee944",
            "bafd6024ee934bfd9813907fc3138b54",
            "0bf1aeb0033646839e365a65cfd30fd5",
            "4d6fa08090a54dd19a9022063b684534",
            "2de6ed0290694b309f48a3b130960c36",
            "6c7a3ac820c140c8a40bc2d873eed4b2",
            "53025ebce26a4bd5a674c17931808f33",
            "e458124e561f4c0cb3b350836d07c7ba",
            "5be3349556004c86a0b6e037a92e5a9c",
            "2271a26b0bd74744a82629be6cf14598",
            "910d801480384851a62bd6e34bd5339c",
            "fe2a5dd0fb93407fb4c22515cdc04d1d",
            "483735a71055407bb7f1a319af2d8a8c",
            "e77f05f5db5740cf9c0448071c81e578",
            "906d395ba6ae4c4194b81b052a753563",
            "879a1d0f6cf044ba800bca85a35756d4",
            "b9e9e9522c5b4702968fccdacca0ef63",
            "fbb233c1d060415aa8756901abd0e5be",
            "1663ea97415a403fa0e1e624076391f1",
            "3372dd3ecd4445908184f89fd138c0b9",
            "65ce3d29f50b4c0f8a3d7bb417430ee5",
            "c9a01b870633496b8340ce927ad45879",
            "6fbf771fe0ca4ca2b6c75365690efec7",
            "9739689ac3274ccc94062955e1bd89bd",
            "0bf41ef364b746afab39a613ff3e1066",
            "d7ef5743f31842a5840cddaef89fdd38",
            "540006618e2a4d389ff21bfcbb59c846",
            "7e79956f596e48029edde89daac4c237",
            "63ea829e0d2647b191e42b7138837f94",
            "265f6ac6ce2d4920b619354e3ad92739",
            "4615a0b3899c41588c372d0f3945f5f0",
            "cba3b9612b5e43b9a3456da1f9460355",
            "d6ed26c87acd46998fcd28e6d5ed7b3e",
            "a88ff4cdd1c2439792bcf00783d4de85",
            "b5fd91342f2548b382a27870566ff42d",
            "c7ba810bd4b64d2a8dfce9e65daac469",
            "56c03f6a2c4e437ea1f0c254d16c22d9",
            "1098cb43d7b14055920ea51d70ba2433",
            "c7ef4ddcd4984e519e139acc96dee03c",
            "12ea7f58175d4b37b983e7ccd05c8442",
            "627e4cf597fb46d5a116f5b217503114",
            "588839d6693946feb92ba56305e79cb5",
            "7e7f69c207394580af8d0bda72aafa69",
            "a7e0649967ab4a4f80958b888f93c834",
            "c3b4e44410714d19b0e912e6241dc4dd",
            "7e161780e18d4cdc9502f6ae9740fa19",
            "b2e2a2225b954aee810594c4a330cce8",
            "d11bb6b8c00b4ef1954dfb7983796c51",
            "38a5d01dbade4689a5308cdba26e3bf2",
            "e6f0524e946a415c981bf093f817743d",
            "b97f71a5281d479681b81737e40e30c5",
            "f8ad0fa57b1b4d7296ebee67a8f9633b",
            "e1ec9b03178e406ca1fc20daaabe0d78",
            "fcd6da10555a49a4a6952a0fdebc81ca",
            "5289f8cfa86145fc8e9e1b980c4408df",
            "38a0711c26e74c7999b9867049d189d2",
            "2255004fe3694f749f4c28775d32ba91",
            "9fbfe0d205ce43ad804553634e888c6f",
            "be794a8caf4c458e904c1650a724cdaf",
            "d968cb72c6264284be601444726587a8",
            "799ddc0c7e324c4f87d6152cd88bed9a",
            "b2b06e4f964a48a48822bc68ed17d41c",
            "29567b88e30e4918b00163ef71e600b4",
            "5162df791f9645e2ad986eb30a479cce",
            "95b7be83949346ecb43826fa57120273",
            "4db229147e204e499c5417e03352c713"
          ]
        },
        "id": "PL6sfeK21Ilo",
        "outputId": "94933316-9140-4115-b589-b84a64b8ebdb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30bb4cfa1ce14d8797783941027ee944"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe2a5dd0fb93407fb4c22515cdc04d1d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fbf771fe0ca4ca2b6c75365690efec7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a88ff4cdd1c2439792bcf00783d4de85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3b4e44410714d19b0e912e6241dc4dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38a0711c26e74c7999b9867049d189d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c49ca48fa524>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Get the final summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mfinal_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-c49ca48fa524>\u001b[0m in \u001b[0;36msummarize_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msummarize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0msummarized_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msummarize_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-c49ca48fa524>\u001b[0m in \u001b[0;36mchunk_text\u001b[0;34m(text, max_tokens)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchunk_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mcurrent_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'facebook/bart-large-cnn'\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "def chunk_text(text, max_tokens=512):\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    current_length = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = tokenizer.encode(sentence, add_special_tokens=False)\n",
        "        if current_length + len(tokens) < max_tokens:\n",
        "            current_chunk += \" \" + sentence\n",
        "            current_length += len(tokens)\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence\n",
        "            current_length = len(tokens)\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def summarize_chunk(chunk):\n",
        "    inputs = tokenizer.encode(chunk, return_tensors='pt', max_length=1024, truncation=True)\n",
        "    summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "def summarize_text(text):\n",
        "    chunks = chunk_text(text)\n",
        "    summarized_chunks = [summarize_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine summaries and optionally run a final summary on the combined text\n",
        "    combined_summary = \" \".join(summarized_chunks)\n",
        "    final_summary = summarize_chunk(combined_summary)\n",
        "\n",
        "    return final_summary\n",
        "\n",
        "# Example text\n",
        "text = \"\"\"Hello all, my name is Krushnayak and welcome to my YouTube channel. So guys before the start of every new year, I usually plan that what all skill sets I really need to add in my bucket list so that I'll be able to teach you all. I will be also able to show you that how specifically it is used in industries. In 2023, you know, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects. I have covered a lot many MLops platform tools, you know, and I've shown each and everything, which was really beneficial for many people out there who really want to make successful career transition into the data science industry. And MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there. So many tools in generative AI have actually come frameworks, libraries and many more things. So MLops will still be there in 2024. But my main aim in 2023 was to understand all about different MLops platform and try to create videos, try to upgrade myself with respect to all those skill sets and provide those videos to you. This was very beneficial. Many people were able to make successful career transition. Now in 2024, I'm also going to focus. See in 2023 also from past three to four months, I'm really much focused in generative AI solving amazing use cases, trying to see multiple frameworks, trying to see multiple LLM models, how you can fine tune it, how you can probably use it in business use cases. And based on that, I'm also creating projects. But majorly in 2024, right, the weightage between MLops and generative AI, I will try to put my most of the weightage in understanding different, different frameworks, cloud platforms, techniques in business use cases in the field of generative AI. So in this video, like if you are also interested and obviously you can see the growth in generative area, how it is happening every other day, some new things are actually coming, right? Let it be models, let it be LLM models, the recent launch of Google Gemini. I know that Gemini did not provide you the right kind of demo video. But other than that, you have Mistral 7B, you have OpenAI, GPD for turbo, right? All these models are specifically coming. Now people are using this in creating amazing AI applications. And you can see there are a lot of startups from image to text, text to image. There are so many different things. I was just seeing one AI platform today, you know, it is basically called as Pickalabs. You just give a prompt and it will try to create an amazing video for you, right? And just imagine you don't even require a video editing any person over there, right? And this is super easy, right? When you probably see this kind of application. So 2024, I'm going to completely focus most of my, if I say 100% from 100%, I'm going to focus 60 to 70% in generative AI and 30% with respect to MLOps platform. And don't worry, every videos that I probably learn will be coming in the form of YouTube channel. But in this video, if you are also really interested to understand about generative AI, I've created an amazing roadmap to learn generative AI in 2024. And this will be specifically for two kinds of roles, which I'm actually going to discuss. And this roadmap, trust me, it has some prerequisites. I'm also going to provide you some videos over here, because if you just cover those prerequisites, that will be more than sufficient to start with generative AI. Yeah. And this is for all those people who are really interested to work in the data field, right? Data analytics field. If you're a developer, if you probably want to work into the generative AI, I think you don't even require this prerequisite. And I'll also call out that specific information over here in my GitHub. Once I probably show you the specific roadmap. So let me go ahead and let me share my screen. So this is the roadmap to learn generative AI. So here you can probably see everything is there. I've provided videos link, I have everything, the prerequisites that is actually required. Everything is mentioned over here. And please make sure that you fork this repository, keep a star on it, because 2024, I am going to really create a lot many things over here. It'll be quite amazing, right? Many, many things will be coming with respect to projects, with respect to frameworks, with respect to what are things I'm going to specifically cover in Lanch in everything, right? So let's start and let's understand this particular roadmap. Before you go ahead, please make sure that you hit like for this particular video will target at 2000 likes at least, you know, because this will be super beneficial because here you're going to get all the videos, all the materials, everything in front of you with respect to the prerequisites. Now I will talk about two different profiles over here. One profile is that if you want to get into the data analytics industry, and let's say you want to probably start if you're starting from scratch, okay, starting from scratch, or from past two years, you're also already in the data analytics field, you're learning about data science, what kind of upgradation you can basically do. The second type of people will be core developers, right? So in my company also, we have used generative AI, we are creating support systems, we are creating assignment, Q&A systems, many more things are there. Right now those developers are specifically creating and they don't have need to have all the knowledge with respect to some kind of prerequisites as such directly they can start with generative AI. So I will be talking about both of them step by step will try to understand. So the roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language. I will again prefer Python programming language because trust me any LLM models that is probably coming from hugging face to open AI to Mistral everywhere Python SDK is there, right? So Python SDK with the help of Python programming language, you will be able to access those API's, you'll be able to probably work on them, you will be able to probably implement any kind of applications. And not only that, you'll also be able to deploy because they are good cloud platforms that are specifically come with respect to that. Okay, so here, Python programming language, I have given this particular link, see, I've already created Python programming language in English in Hindi, we'll be able to probably find out all this particular videos. I've already shown you this particular videos, good videos, if you probably see there are millions and millions of views with respect to this all videos. Again at the end of the day, this will be super beneficial for everyone out there, right? And not only this Python, if you just want to also become a Python programmer, everything is covered from modular coding to inheritance to oops constant, everything is probably explained along with materials. So this is the first thing. Now here, in third and fourth, I have also added some frameworks playlist, right? Like what like Flask playlist, fast API tutorials and all, right? So these are frameworks, streamlet is one framework, different different frameworks you can specifically use, okay? It is up to you. See, I've created videos on streamlet also I've created videos on Gradio also, but I've just given two frameworks over here Flask and fast API to just give you an idea. If you search for streamlet in my YouTube channel, you'll be able to get those videos also. So Python is the first thing, okay? Usually if you are from another like other like core, if you are directly a developer, you have working in applications, you're creating like full stack web developer, you're having those kind of position. And let's say someone comes and tells you, okay, go ahead and apply this generative way. I think in our project, try to create a chat bot, try to create something. At that time, you don't require Python, whatever will be a core language like JavaScript or you can go ahead with that because that kind of SDK is also provided. But this is specifically with respect to the data field. Now coming to the next thing, see, over here, the roadmap that I'm talking about generative AI, this is with respect to LLM models, I'm not talking about large image models, okay? What I feel is that computer vision, large image models is also good. But the kind of kind of update, upgradation that are specifically happening is with respect to LLM models. This is the one thing that I'm talking about this roadmap, I really want to make it for understanding like how you can become better in generative AI in the field of LLM applications, okay, large language model. Whenever I say large language model, I'm basically talking about NLP. Okay? I am not exploring much in large image models because computer vision, I too don't have that much interest. So in my YouTube channel, so you'll be finding videos that I have not uploaded much with respect to computer vision, okay? But I'm really interested in NLP. So after completing Python, you will basically be having the basic machine learning natural language processing. Again, this is basically the prerequisites, okay? And here I've given, I've taken already natural language processing live session where I've covered in five days all these topics, YNLP, one-hot encoding, bag of words, TF-IDF, word to beck, average word to beck, and there are a lot many topics that I've actually covered, which you will be able to find over here from day one to day five. So if I probably go ahead and open this particular video here from day one to day five, you'll be getting everything like word embedding, C bow, what is skip gram, word to beck. This five video will be able to help you understand because see, this is a very good roadmap, a prerequisite, a short roadmap. I'm not going to make a very big roadmap because this concept is basically used so that you understand them. What is vectors? You know, how we convert text into a numerical variable. All these things will be important for your interview because in the interview, they'll not directly are generated way, I think. They'll first of all see how good your basics is, right? So considering this, here I could add more topics over here based on this day one to day five, but your task is as a prerequisite is to basically see this day one to day five. And this also includes practical implementation. Now the third day, third part is that you need to cover basic deep learning concepts. Now when I say basic deep learning concepts, this is something related to ANN, like how does a multilayer neural network work? What is perceptron? What is forward propagation, backward propagation, activation function, loss function optimizers? What is weight initialization techniques? What is vanishing gradient problem? Everything right over here. Again I have not written much topic so that you don't look, it does not look very big for you and you don't get demotivated. But all these concepts, again I have made a live playlist in my community series that is regarding day one to day five. So if you probably open this link, okay. So here you'll be able to see day one to day five. After day five, if I see this deep learning concept. So what I will do, I will open my YouTube channel and I'll write Krishnayak live deep learning, okay. So I will update those link over there. And here you have, right, so this is basically your live deep learning sessions, okay. So here you can probably see this day one to day five. This is basically the prerequisite, right. All the important things, how does forward propagation work? What is chain rule of derivatives? What exactly is optimizers? What exactly is loss function? What is forward propagation, backward propagation? The CNN I have actually implemented and shown in the practical way. So this link I will try to update it over here, right. So in basic deep learning concept, this is must. Because unless you don't understand that, the further topics will not be able to understand. This is the smartest way that I've actually created a roadmap where unnecessary jargons need not be added, okay. Then after you complete this, then we go to the advanced NLP concept. Now advanced NLP concept is nothing but day six to last video. Which one? If you probably click this link, here you'll be able to see six to entire tilt transformer. So here you can see day six, day seven. Here I've discussed about RNN. Here I've discussed about back propagation in RNN, LHTMRNN, word embedding, LHTM practical implementation, advanced LNM series, bidirectional LHTM, transformers, encoder, decoder. Everything is basically covered in all the specific videos. So if you are able to cover this from day six to probably 13th or 14th video, all these topics will be easily covered. If you are not able to find some topic, go and search for that topic with my name over there. I have a lot of videos. I have 1800 plus videos in my YouTube channel. When I've covered everything and this is what I've done from past three years, all the basics concepts have made strong so that you can clear the interview. There is no query that you cannot clear the interview guys. The kind of content that I've put in my YouTube channel is completely from free scratch, everything from basics so that you learn any advanced thing. It will be very much easy for you to crack the interview. So that is what my advanced NLP concept says where my main aim was to cover the transformer because after that, whenever you start your generative AI, that basically means most of your models are in the form of transformers or BERT, right? So here you have GPT-4, Mistral 7B. So here is where you probably start your journey. This is what is the prerequisite till here, right? And that is the reason I've created this prerequisite in this specific way. And it is simple. It's more about learn to the point, right? Don't waste your time much. Learn to the point, see some practical implementation because I don't think so this kind of practical implementation you will be doing in the industry also. But yes, in the interview, they may ask you now for those people who are directly developer, they can also jump in this particular topic, right? They can directly start from here because at the end of the day, they are very good at development, you know, who are full stack web developer who are working in the software engineering field, they can directly use these APIs and they can implement it. Now if I talk about some important things over here, right? Starting the journey towards generative AI. You need to really be very much open minded in probably doing a research on all these models, right? So Mistral 7b, Lama, Lama index, hugging face, open source libraries, Google Palm model and all, right? I've written over here because there are a lot of updates that are coming with respect to the specific models. And I'll tell you GPT-4 is must, hugging face is must, Lama, Mistral 7b, Mistral 7b has now recently come up with one amazing model. Again, we say it as a 87 cross B, right? Something like that. I'll be talking more about those models as we go ahead, right? And also try to see open source LNM models because with all this help of these models, you know, you can develop any business use cases that are specifically related to NLP, right? NLP, natural language processing, any use cases, chatbot to text summarization to documentation, anything, quiz, anything. So that is specifically required for the companies, you will be able to do this, right? And that is the reason why many companies are specifically using it. Large image models also you can use because all this large image models they'll be providing your diffusion models, they'll be providing your Dali, right? And based on that, you can do all further on top of it. But really, I'm focusing more on LLMs right now. So the first thing is OpenAI. It has amazing documentation link. Have already created videos, good playlist of videos over here, you can definitely look it out. And this documentation you really need to be good at. And the best thing about this documentation in OpenAI, it provides a good amazing things, right? OpenAI, start with this. Videos are given, you can definitely refer it. This year, I'm going to target LangChain like anything. LangChain, already if you go and see my YouTube playlist, they are on 10 to 12 videos. But LangChain is one amazing library that acts as a wrapper on top of OpenAI. It can also use hugging face. It has so many different functionalities to create all the LLM models, not only this. So LangChain also provides deployment techniques like LangServ, chain rest as rest APIs. This is nothing but it is entirely called as LangSmith. So you can probably see this is your LangChain application. It may be in Python, it may be in JavaScript. On top of that, you will be creating some template, you will be doing the deployment in the form of APIs by using this LangSmith. So going forward, I really want to probably see this entire tool and deployment techniques also and it is very much it is recently been announced, right? Why I like LangChain is that because it has so many different functionalities over here, right? Different functionalities from chatbots to prompts to modules to probably if you go and see right, what is LangServ will be releasing a hosted version of LangServ from one click deployment. Just imagine just one click deployment. All these things we are going to explore like anything as we go ahead, right? In LLMs, what exactly is unsync API, dissolve, prompting, most of the videos that I have already created, but every day I see something is getting added in this documentation, right? Over here only, if you probably see with respect to retrieval, right? In document loader, like which all documents will be able to load like CSV, file directory, HTML, JSON, markdown, PDF, document transformer, how do you split the documents and all, everything. But most of this everything will be combined in the form of a project in the end to end project where I do the deployment in an amazing way, right? All those things will basically be covered and here is a detailed video. After I get a good expertise on LangChain, I will also be starting with Chainlit. So Chainlit is another one documentation which looks very good over here, right? Good you will be able to do everything with the help of LangChain, Lama index, here also it is supported. You will also be able to do the deployment, right? Everything is there. You can do it in AWS, Azure, Google route, Replate, render, fly.io, hugging face spaces, okay? So once you probably cover this, right now in these two years you can probably target OpenAI and LangChain and Chainlit, okay? That is what I am actually going to do and based on this I will try to create a lot of videos, okay? LangChain, again you can interact with hugging face models, Lama, Mistral 7b, anything as such, whatever you want, okay? The next topic that you really need to focus is about vector databases and vector stores. Now vector database will play a very important role and again this will again be a part of LangChain itself because in LangChain it provides you functionalities. Some of the vector databases that I have already explored is like ChromaDB, FIAS. It is FIAS vector database is nothing but which makes use of Facebook AI similarity search library, right? So this is coming from Facebook. LandDB vector database based on the Lange data format. So there is a format which is called as Lange data set and again there you will be able to apply similarity search. Cassandra DB for storing vectors, Cassandra DB is also amazing, MongoDB is also amazing, right? At the end of the day, if you have any text you really want to convert that into vectors and since it is for the performance sake you really need to store it in some kind of vector database so that you can retrieve it and enjoy it. Then finally after doing this you have to probably do the deployment of LLM projects and this is what I am going to target. Within one month you will find all these videos in my YouTube channel, right? In AWS, Azure, LangSmith, LangSpa, HuggingFace, wherever you want to do the deployment. And finally guys if you really want to go ahead and check like how does, what is GenitiveAI, whether GenitiveAI is there for nano. I have given the course link over here, okay? This is a free community course where everybody can probably apply for it. You will find all the videos, materials and all and it is live series. Right now we are in day 5, day 6. So please go ahead and check it out, it is completely for free. See whether GenitiveAI is for you or not. And I hope if you are already in the data field I feel you really need to go towards GenitiveAI, right? At the end of the day. Because for the interview sake, yes, basic questions will be asked. But when you implement things in the production level, this all will be very much handy. And this is what is my main aim in 2024. I hope you like this particular video. Yes, please go ahead. Right now this is in private, I will make it public. So let me go ahead and make it public. So I will change it to public so that you can also access it. Make this repository public. And now one final thing is that I will also update this specific link of deep learning. So I hope you like this particular video. This was it from my side. I will see you all in the next video. Have a great day. Thank you and all. Take care. Bye bye.\"\"\"\n",
        "\n",
        "# Get the final summary\n",
        "final_summary = summarize_text(text)\n",
        "print(final_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-diqTy61YcN",
        "outputId": "9351cc2d-6ff8-4526-f536-9e84e7e3078f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In 2023, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects. MLops, I think in 2024 also it will play a very important role. The roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Load the BART model and tokenizer\n",
        "model_name = 'facebook/bart-large-cnn'\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "def chunk_text(text, max_tokens=512):\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    current_length = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = tokenizer.encode(sentence, add_special_tokens=False)\n",
        "        if current_length + len(tokens) < max_tokens:\n",
        "            current_chunk += \" \" + sentence\n",
        "            current_length += len(tokens)\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence\n",
        "            current_length = len(tokens)\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def summarize_chunk(chunk):\n",
        "    inputs = tokenizer.encode(chunk, return_tensors='pt', max_length=1024, truncation=True)\n",
        "    summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "def summarize_text(text):\n",
        "    chunks = chunk_text(text)\n",
        "    summarized_chunks = [summarize_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine summaries as paragraphs\n",
        "    combined_summary = \"\\n\\n\".join(summarized_chunks)\n",
        "    return combined_summary\n",
        "\n",
        "# Example text\n",
        "text = \"\"\"Hello all, my name is Krushnayak and welcome to my YouTube channel. So guys before the start of every new year, I usually plan that what all skill sets I really need to add in my bucket list so that I'll be able to teach you all. I will be also able to show you that how specifically it is used in industries. In 2023, you know, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects. I have covered a lot many MLops platform tools, you know, and I've shown each and everything, which was really beneficial for many people out there who really want to make successful career transition into the data science industry. And MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there. So many tools in generative AI have actually come frameworks, libraries and many more things. So MLops will still be there in 2024. But my main aim in 2023 was to understand all about different MLops platform and try to create videos, try to upgrade myself with respect to all those skill sets and provide those videos to you. This was very beneficial. Many people were able to make successful career transition. Now in 2024, I'm also going to focus. See in 2023 also from past three to four months, I'm really much focused in generative AI solving amazing use cases, trying to see multiple frameworks, trying to see multiple LLM models, how you can fine tune it, how you can probably use it in business use cases. And based on that, I'm also creating projects. But majorly in 2024, right, the weightage between MLops and generative AI, I will try to put my most of the weightage in understanding different, different frameworks, cloud platforms, techniques in business use cases in the field of generative AI. So in this video, like if you are also interested and obviously you can see the growth in generative area, how it is happening every other day, some new things are actually coming, right? Let it be models, let it be LLM models, the recent launch of Google Gemini. I know that Gemini did not provide you the right kind of demo video. But other than that, you have Mistral 7B, you have OpenAI, GPD for turbo, right? All these models are specifically coming. Now people are using this in creating amazing AI applications. And you can see there are a lot of startups from image to text, text to image. There are so many different things. I was just seeing one AI platform today, you know, it is basically called as Pickalabs. You just give a prompt and it will try to create an amazing video for you, right? And just imagine you don't even require a video editing any person over there, right? And this is super easy, right? When you probably see this kind of application. So 2024, I'm going to completely focus most of my, if I say 100% from 100%, I'm going to focus 60 to 70% in generative AI and 30% with respect to MLOps platform. And don't worry, every videos that I probably learn will be coming in the form of YouTube channel. But in this video, if you are also really interested to understand about generative AI, I've created an amazing roadmap to learn generative AI in 2024. And this will be specifically for two kinds of roles, which I'm actually going to discuss. And this roadmap, trust me, it has some prerequisites. I'm also going to provide you some videos over here, because if you just cover those prerequisites, that will be more than sufficient to start with generative AI. Yeah. And this is for all those people who are really interested to work in the data field, right? Data analytics field. If you're a developer, if you probably want to work into the generative AI, I think you don't even require this prerequisite. And I'll also call out that specific information over here in my GitHub. Once I probably show you the specific roadmap. So let me go ahead and let me share my screen. So this is the roadmap to learn generative AI. So here you can probably see everything is there. I've provided videos link, I have everything, the prerequisites that is actually required. Everything is mentioned over here. And please make sure that you fork this repository, keep a star on it, because 2024, I am going to really create a lot many things over here. It'll be quite amazing, right? Many, many things will be coming with respect to projects, with respect to frameworks, with respect to what are things I'm going to specifically cover in Lanch in everything, right? So let's start and let's understand this particular roadmap. Before you go ahead, please make sure that you hit like for this particular video will target at 2000 likes at least, you know, because this will be super beneficial because here you're going to get all the videos, all the materials, everything in front of you with respect to the prerequisites. Now I will talk about two different profiles over here. One profile is that if you want to get into the data analytics industry, and let's say you want to probably start if you're starting from scratch, okay, starting from scratch, or from past two years, you're also already in the data analytics field, you're learning about data science, what kind of upgradation you can basically do. The second type of people will be core developers, right? So in my company also, we have used generative AI, we are creating support systems, we are creating assignment, Q&A systems, many more things are there. Right now those developers are specifically creating and they don't have need to have all the knowledge with respect to some kind of prerequisites as such directly they can start with generative AI. So I will be talking about both of them step by step will try to understand. So the roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language. I will again prefer Python programming language because trust me any LLM models that is probably coming from hugging face to open AI to Mistral everywhere Python SDK is there, right? So Python SDK with the help of Python programming language, you will be able to access those API's, you'll be able to probably work on them, you will be able to probably implement any kind of applications. And not only that, you'll also be able to deploy because they are good cloud platforms that are specifically come with respect to that. Okay, so here, Python programming language, I have given this particular link, see, I've already created Python programming language in English in Hindi, we'll be able to probably find out all this particular videos. I've already shown you this particular videos, good videos, if you probably see there are millions and millions of views with respect to this all videos. Again at the end of the day, this will be super beneficial for everyone out there, right? And not only this Python, if you just want to also become a Python programmer, everything is covered from modular coding to inheritance to oops constant, everything is probably explained along with materials. So this is the first thing. Now here, in third and fourth, I have also added some frameworks playlist, right? Like what like Flask playlist, fast API tutorials and all, right? So these are frameworks, streamlet is one framework, different different frameworks you can specifically use, okay? It is up to you. See, I've created videos on streamlet also I've created videos on Gradio also, but I've just given two frameworks over here Flask and fast API to just give you an idea. If you search for streamlet in my YouTube channel, you'll be able to get those videos also. So Python is the first thing, okay? Usually if you are from another like other like core, if you are directly a developer, you have working in applications, you're creating like full stack web developer, you're having those kind of position. And let's say someone comes and tells you, okay, go ahead and apply this generative way. I think in our project, try to create a chat bot, try to create something. At that time, you don't require Python, whatever will be a core language like JavaScript or you can go ahead with that because that kind of SDK is also provided. But this is specifically with respect to the data field. Now coming to the next thing, see, over here, the roadmap that I'm talking about generative AI, this is with respect to LLM models, I'm not talking about large image models, okay? What I feel is that computer vision, large image models is also good. But the kind of kind of update, upgradation that are specifically happening is with respect to LLM models. This is the one thing that I'm talking about this roadmap, I really want to make it for understanding like how you can become better in generative AI in the field of LLM applications, okay, large language model. Whenever I say large language model, I'm basically talking about NLP. Okay? I am not exploring much in large image models because computer vision, I too don't have that much interest. So in my YouTube channel, so you'll be finding videos that I have not uploaded much with respect to computer vision, okay? But I'm really interested in NLP. So after completing Python, you will basically be having the basic machine learning natural language processing. Again, this is basically the prerequisites, okay? And here I've given, I've taken already natural language processing live session where I've covered in five days all these topics, YNLP, one-hot encoding, bag of words, TF-IDF, word to beck, average word to beck, and there are a lot many topics that I've actually covered, which you will be able to find over here from day one to day five. So if I probably go ahead and open this particular video here from day one to day five, you'll be getting everything like word embedding, C bow, what is skip gram, word to beck. This five video will be able to help you understand because see, this is a very good roadmap, a prerequisite, a short roadmap. I'm not going to make a very big roadmap because this concept is basically used so that you understand them. What is vectors? You know, how we convert text into a numerical variable. All these things will be important for your interview because in the interview, they'll not directly are generated way, I think. They'll first of all see how good your basics is, right? So considering this, here I could add more topics over here based on this day one to day five, but your task is as a prerequisite is to basically see this day one to day five. And this also includes practical implementation. Now the third day, third part is that you need to cover basic deep learning concepts. Now when I say basic deep learning concepts, this is something related to ANN, like how does a multilayer neural network work? What is perceptron? What is forward propagation, backward propagation, activation function, loss function optimizers? What is weight initialization techniques? What is vanishing gradient problem? Everything right over here. Again I have not written much topic so that you don't look, it does not look very big for you and you don't get demotivated. But all these concepts, again I have made a live playlist in my community series that is regarding day one to day five. So if you probably open this link, okay. So here you'll be able to see day one to day five. After day five, if I see this deep learning concept. So what I will do, I will open my YouTube channel and I'll write Krishnayak live deep learning, okay. So I will update those link over there. And here you have, right, so this is basically your live deep learning sessions, okay. So here you can probably see this day one to day five. This is basically the prerequisite, right. All the important things, how does forward propagation work? What is chain rule of derivatives? What exactly is optimizers? What exactly is loss function? What is forward propagation, backward propagation? The CNN I have actually implemented and shown in the practical way. So this link I will try to update it over here, right. So in basic deep learning concept, this is must. Because unless you don't understand that, the further topics will not be able to understand. This is the smartest way that I've actually created a roadmap where unnecessary jargons need not be added, okay. Then after you complete this, then we go to the advanced NLP concept. Now advanced NLP concept is nothing but day six to last video. Which one? If you probably click this link, here you'll be able to see six to entire tilt transformer. So here you can see day six, day seven. Here I've discussed about RNN. Here I've discussed about back propagation in RNN, LHTMRNN, word embedding, LHTM practical implementation, advanced LNM series, bidirectional LHTM, transformers, encoder, decoder. Everything is basically covered in all the specific videos. So if you are able to cover this from day six to probably 13th or 14th video, all these topics will be easily covered. If you are not able to find some topic, go and search for that topic with my name over there. I have a lot of videos. I have 1800 plus videos in my YouTube channel. When I've covered everything and this is what I've done from past three years, all the basics concepts have made strong so that you can clear the interview. There is no query that you cannot clear the interview guys. The kind of content that I've put in my YouTube channel is completely from free scratch, everything from basics so that you learn any advanced thing. It will be very much easy for you to crack the interview. So that is what my advanced NLP concept says where my main aim was to cover the transformer because after that, whenever you start your generative AI, that basically means most of your models are in the form of transformers or BERT, right? So here you have GPT-4, Mistral 7B. So here is where you probably start your journey. This is what is the prerequisite till here, right? And that is the reason I've created this prerequisite in this specific way. And it is simple. It's more about learn to the point, right? Don't waste your time much. Learn to the point, see some practical implementation because I don't think so this kind of practical implementation you will be doing in the industry also. But yes, in the interview, they may ask you now for those people who are directly developer, they can also jump in this particular topic, right? They can directly start from here because at the end of the day, they are very good at development, you know, who are full stack web developer who are working in the software engineering field, they can directly use these APIs and they can implement it. Now if I talk about some important things over here, right? Starting the journey towards generative AI. You need to really be very much open minded in probably doing a research on all these models, right? So Mistral 7b, Lama, Lama index, hugging face, open source libraries, Google Palm model and all, right? I've written over here because there are a lot of updates that are coming with respect to the specific models. And I'll tell you GPT-4 is must, hugging face is must, Lama, Mistral 7b, Mistral 7b has now recently come up with one amazing model. Again, we say it as a 87 cross B, right? Something like that. I'll be talking more about those models as we go ahead, right? And also try to see open source LNM models because with all this help of these models, you know, you can develop any business use cases that are specifically related to NLP, right? NLP, natural language processing, any use cases, chatbot to text summarization to documentation, anything, quiz, anything. So that is specifically required for the companies, you will be able to do this, right? And that is the reason why many companies are specifically using it. Large image models also you can use because all this large image models they'll be providing your diffusion models, they'll be providing your Dali, right? And based on that, you can do all further on top of it. But really, I'm focusing more on LLMs right now. So the first thing is OpenAI. It has amazing documentation link. Have already created videos, good playlist of videos over here, you can definitely look it out. And this documentation you really need to be good at. And the best thing about this documentation in OpenAI, it provides a good amazing things, right? OpenAI, start with this. Videos are given, you can definitely refer it. This year, I'm going to target LangChain like anything. LangChain, already if you go and see my YouTube playlist, they are on 10 to 12 videos. But LangChain is one amazing library that acts as a wrapper on top of OpenAI. It can also use hugging face. It has so many different functionalities to create all the LLM models, not only this. So LangChain also provides deployment techniques like LangServ, chain rest as rest APIs. This is nothing but it is entirely called as LangSmith. So you can probably see this is your LangChain application. It may be in Python, it may be in JavaScript. On top of that, you will be creating some template, you will be doing the deployment in the form of APIs by using this LangSmith. So going forward, I really want to probably see this entire tool and deployment techniques also and it is very much it is recently been announced, right? Why I like LangChain is that because it has so many different functionalities over here, right? Different functionalities from chatbots to prompts to modules to probably if you go and see right, what is LangServ will be releasing a hosted version of LangServ from one click deployment. Just imagine just one click deployment. All these things we are going to explore like anything as we go ahead, right? In LLMs, what exactly is unsync API, dissolve, prompting, most of the videos that I have already created, but every day I see something is getting added in this documentation, right? Over here only, if you probably see with respect to retrieval, right? In document loader, like which all documents will be able to load like CSV, file directory, HTML, JSON, markdown, PDF, document transformer, how do you split the documents and all, everything. But most of this everything will be combined in the form of a project in the end to end project where I do the deployment in an amazing way, right? All those things will basically be covered and here is a detailed video. After I get a good expertise on LangChain, I will also be starting with Chainlit. So Chainlit is another one documentation which looks very good over here, right? Good you will be able to do everything with the help of LangChain, Lama index, here also it is supported. You will also be able to do the deployment, right? Everything is there. You can do it in AWS, Azure, Google route, Replate, render, fly.io, hugging face spaces, okay? So once you probably cover this, right now in these two years you can probably target OpenAI and LangChain and Chainlit, okay? That is what I am actually going to do and based on this I will try to create a lot of videos, okay? LangChain, again you can interact with hugging face models, Lama, Mistral 7b, anything as such, whatever you want, okay? The next topic that you really need to focus is about vector databases and vector stores. Now vector database will play a very important role and again this will again be a part of LangChain itself because in LangChain it provides you functionalities. Some of the vector databases that I have already explored is like ChromaDB, FIAS. It is FIAS vector database is nothing but which makes use of Facebook AI similarity search library, right? So this is coming from Facebook. LandDB vector database based on the Lange data format. So there is a format which is called as Lange data set and again there you will be able to apply similarity search. Cassandra DB for storing vectors, Cassandra DB is also amazing, MongoDB is also amazing, right? At the end of the day, if you have any text you really want to convert that into vectors and since it is for the performance sake you really need to store it in some kind of vector database so that you can retrieve it and enjoy it. Then finally after doing this you have to probably do the deployment of LLM projects and this is what I am going to target. Within one month you will find all these videos in my YouTube channel, right? In AWS, Azure, LangSmith, LangSpa, HuggingFace, wherever you want to do the deployment. And finally guys if you really want to go ahead and check like how does, what is GenitiveAI, whether GenitiveAI is there for nano. I have given the course link over here, okay? This is a free community course where everybody can probably apply for it. You will find all the videos, materials and all and it is live series. Right now we are in day 5, day 6. So please go ahead and check it out, it is completely for free. See whether GenitiveAI is for you or not. And I hope if you are already in the data field I feel you really need to go towards GenitiveAI, right? At the end of the day. Because for the interview sake, yes, basic questions will be asked. But when you implement things in the production level, this all will be very much handy. And this is what is my main aim in 2024. I hope you like this particular video. Yes, please go ahead. Right now this is in private, I will make it public. So let me go ahead and make it public. So I will change it to public so that you can also access it. Make this repository public. And now one final thing is that I will also update this specific link of deep learning. So I hope you like this particular video. This was it from my side. I will see you all in the next video. Have a great day. Thank you and all. Take care. Bye bye.\"\"\"\n",
        "\n",
        "# Get the summary\n",
        "final_summary = summarize_text(text)\n",
        "print(final_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJe-O4a5161C",
        "outputId": "7587ff4f-f07e-4046-dd39-da53e2c6a235"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In 2023, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects. MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there.\n",
            "\n",
            "All these models are specifically coming. Now people are using this in creating amazing AI applications. And you can see there are a lot of startups from image to text, text to image. There are so many different things. I was just seeing one AI platform today, you know, it is basically called as Pickalabs. You just give a prompt and it will try to create an amazing video for you, right?\n",
            "\n",
            "The roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language. I will again prefer Python programming language because trust me any LLM models that is probably coming from hugging face to open AI to Mistral everywhere Python SDK is there.\n",
            "\n",
            "Python is the first thing, okay? Usually if you are from another like other like core, if you have working in applications, you're creating like full stack web developer. And let's say someone comes and tells you, okay, go ahead and apply this generative way. At that time, you don't require Python, whatever will be a core language like JavaScript or you can go ahead with that because that kind of SDK is also provided. But this is specifically with respect to the data field. Now coming to the next thing, see, over here, the roadmap that I'm talking about generative AI, I'm not talking about large image models.\n",
            "\n",
            "Krishnayak: I've taken already natural language processing live session where I've covered in five days all these topics. So if I probably go ahead and open this particular video here from day one to day five, you'll be getting everything like word embedding, C bow, what is skip gram, word to beck.\n",
            "\n",
            "So in basic deep learning concept, this is must. Because unless you don't understand that, the further topics will not be able to understand. This is the smartest way that I've actually created a roadmap where unnecessary jargons need not be added. Then after you complete this, then we go to the advanced NLP concept.\n",
            "\n",
            "Learn to the point, see some practical implementation because I don't think so this kind of practical implementation you will be doing in the industry also. You need to really be very much open minded in probably doing a research on all these models, right? So Mistral 7b, Lama, Lama index, hugging face, open source libraries, Google Palm model and all.\n",
            "\n",
            "This year, I'm going to target LangChain like anything. LangChain is one amazing library that acts as a wrapper on top of OpenAI. It has so many different functionalities to create all the LLM models, not only this. So LangChain also provides deployment techniques like LangServ.\n",
            "\n",
            "Good you will be able to do everything with the help of LangChain, Lama index, here also it is supported. You can do it in AWS, Azure, Google route, Replate, render, fly.io, hugging face spaces, okay? So once you probably cover this, right now in these two years you can probably target OpenAI and LangChain and Chainlit. That is what I am actually going to do.\n",
            "\n",
            "So please go ahead and check it out, it is completely for free. See whether GenitiveAI is for you or not. And I hope if you are already in the data field I feel you really need to go towards Genitive AI, right? At the end of the day.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "# from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Load the BART model and tokenizer\n",
        "model_name = 'facebook/bart-large-cnn'\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "def chunk_text(text, max_tokens=700):\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    current_length = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = tokenizer.encode(sentence, add_special_tokens=False)\n",
        "        if current_length + len(tokens) < max_tokens:\n",
        "            current_chunk += \" \" + sentence\n",
        "            current_length += len(tokens)\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence\n",
        "            current_length = len(tokens)\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def summarize_chunk(chunk):\n",
        "    inputs = tokenizer.encode(chunk, return_tensors='pt', max_length=1024, truncation=True)\n",
        "    summary_ids = model.generate(inputs, max_length=500, min_length=60, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "def summarize_text(text):\n",
        "    chunks = chunk_text(text)\n",
        "    summarized_chunks = [summarize_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine summaries as paragraphs\n",
        "    combined_summary = \"\\n\\n\".join(summarized_chunks)\n",
        "    return combined_summary\n",
        "\n",
        "# Example text\n",
        "text = \"\"\"Hello all, my name is Krushnayak and welcome to my YouTube channel. So guys before the start of every new year, I usually plan that what all skill sets I really need to add in my bucket list so that I'll be able to teach you all. I will be also able to show you that how specifically it is used in industries. In 2023, you know, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects. I have covered a lot many MLops platform tools, you know, and I've shown each and everything, which was really beneficial for many people out there who really want to make successful career transition into the data science industry. And MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there. So many tools in generative AI have actually come frameworks, libraries and many more things. So MLops will still be there in 2024. But my main aim in 2023 was to understand all about different MLops platform and try to create videos, try to upgrade myself with respect to all those skill sets and provide those videos to you. This was very beneficial. Many people were able to make successful career transition. Now in 2024, I'm also going to focus. See in 2023 also from past three to four months, I'm really much focused in generative AI solving amazing use cases, trying to see multiple frameworks, trying to see multiple LLM models, how you can fine tune it, how you can probably use it in business use cases. And based on that, I'm also creating projects. But majorly in 2024, right, the weightage between MLops and generative AI, I will try to put my most of the weightage in understanding different, different frameworks, cloud platforms, techniques in business use cases in the field of generative AI. So in this video, like if you are also interested and obviously you can see the growth in generative area, how it is happening every other day, some new things are actually coming, right? Let it be models, let it be LLM models, the recent launch of Google Gemini. I know that Gemini did not provide you the right kind of demo video. But other than that, you have Mistral 7B, you have OpenAI, GPD for turbo, right? All these models are specifically coming. Now people are using this in creating amazing AI applications. And you can see there are a lot of startups from image to text, text to image. There are so many different things. I was just seeing one AI platform today, you know, it is basically called as Pickalabs. You just give a prompt and it will try to create an amazing video for you, right? And just imagine you don't even require a video editing any person over there, right? And this is super easy, right? When you probably see this kind of application. So 2024, I'm going to completely focus most of my, if I say 100% from 100%, I'm going to focus 60 to 70% in generative AI and 30% with respect to MLOps platform. And don't worry, every videos that I probably learn will be coming in the form of YouTube channel. But in this video, if you are also really interested to understand about generative AI, I've created an amazing roadmap to learn generative AI in 2024. And this will be specifically for two kinds of roles, which I'm actually going to discuss. And this roadmap, trust me, it has some prerequisites. I'm also going to provide you some videos over here, because if you just cover those prerequisites, that will be more than sufficient to start with generative AI. Yeah. And this is for all those people who are really interested to work in the data field, right? Data analytics field. If you're a developer, if you probably want to work into the generative AI, I think you don't even require this prerequisite. And I'll also call out that specific information over here in my GitHub. Once I probably show you the specific roadmap. So let me go ahead and let me share my screen. So this is the roadmap to learn generative AI. So here you can probably see everything is there. I've provided videos link, I have everything, the prerequisites that is actually required. Everything is mentioned over here. And please make sure that you fork this repository, keep a star on it, because 2024, I am going to really create a lot many things over here. It'll be quite amazing, right? Many, many things will be coming with respect to projects, with respect to frameworks, with respect to what are things I'm going to specifically cover in Lanch in everything, right? So let's start and let's understand this particular roadmap. Before you go ahead, please make sure that you hit like for this particular video will target at 2000 likes at least, you know, because this will be super beneficial because here you're going to get all the videos, all the materials, everything in front of you with respect to the prerequisites. Now I will talk about two different profiles over here. One profile is that if you want to get into the data analytics industry, and let's say you want to probably start if you're starting from scratch, okay, starting from scratch, or from past two years, you're also already in the data analytics field, you're learning about data science, what kind of upgradation you can basically do. The second type of people will be core developers, right? So in my company also, we have used generative AI, we are creating support systems, we are creating assignment, Q&A systems, many more things are there. Right now those developers are specifically creating and they don't have need to have all the knowledge with respect to some kind of prerequisites as such directly they can start with generative AI. So I will be talking about both of them step by step will try to understand. So the roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language. I will again prefer Python programming language because trust me any LLM models that is probably coming from hugging face to open AI to Mistral everywhere Python SDK is there, right? So Python SDK with the help of Python programming language, you will be able to access those API's, you'll be able to probably work on them, you will be able to probably implement any kind of applications. And not only that, you'll also be able to deploy because they are good cloud platforms that are specifically come with respect to that. Okay, so here, Python programming language, I have given this particular link, see, I've already created Python programming language in English in Hindi, we'll be able to probably find out all this particular videos. I've already shown you this particular videos, good videos, if you probably see there are millions and millions of views with respect to this all videos. Again at the end of the day, this will be super beneficial for everyone out there, right? And not only this Python, if you just want to also become a Python programmer, everything is covered from modular coding to inheritance to oops constant, everything is probably explained along with materials. So this is the first thing. Now here, in third and fourth, I have also added some frameworks playlist, right? Like what like Flask playlist, fast API tutorials and all, right? So these are frameworks, streamlet is one framework, different different frameworks you can specifically use, okay? It is up to you. See, I've created videos on streamlet also I've created videos on Gradio also, but I've just given two frameworks over here Flask and fast API to just give you an idea. If you search for streamlet in my YouTube channel, you'll be able to get those videos also. So Python is the first thing, okay? Usually if you are from another like other like core, if you are directly a developer, you have working in applications, you're creating like full stack web developer, you're having those kind of position. And let's say someone comes and tells you, okay, go ahead and apply this generative way. I think in our project, try to create a chat bot, try to create something. At that time, you don't require Python, whatever will be a core language like JavaScript or you can go ahead with that because that kind of SDK is also provided. But this is specifically with respect to the data field. Now coming to the next thing, see, over here, the roadmap that I'm talking about generative AI, this is with respect to LLM models, I'm not talking about large image models, okay? What I feel is that computer vision, large image models is also good. But the kind of kind of update, upgradation that are specifically happening is with respect to LLM models. This is the one thing that I'm talking about this roadmap, I really want to make it for understanding like how you can become better in generative AI in the field of LLM applications, okay, large language model. Whenever I say large language model, I'm basically talking about NLP. Okay? I am not exploring much in large image models because computer vision, I too don't have that much interest. So in my YouTube channel, so you'll be finding videos that I have not uploaded much with respect to computer vision, okay? But I'm really interested in NLP. So after completing Python, you will basically be having the basic machine learning natural language processing. Again, this is basically the prerequisites, okay? And here I've given, I've taken already natural language processing live session where I've covered in five days all these topics, YNLP, one-hot encoding, bag of words, TF-IDF, word to beck, average word to beck, and there are a lot many topics that I've actually covered, which you will be able to find over here from day one to day five. So if I probably go ahead and open this particular video here from day one to day five, you'll be getting everything like word embedding, C bow, what is skip gram, word to beck. This five video will be able to help you understand because see, this is a very good roadmap, a prerequisite, a short roadmap. I'm not going to make a very big roadmap because this concept is basically used so that you understand them. What is vectors? You know, how we convert text into a numerical variable. All these things will be important for your interview because in the interview, they'll not directly are generated way, I think. They'll first of all see how good your basics is, right? So considering this, here I could add more topics over here based on this day one to day five, but your task is as a prerequisite is to basically see this day one to day five. And this also includes practical implementation. Now the third day, third part is that you need to cover basic deep learning concepts. Now when I say basic deep learning concepts, this is something related to ANN, like how does a multilayer neural network work? What is perceptron? What is forward propagation, backward propagation, activation function, loss function optimizers? What is weight initialization techniques? What is vanishing gradient problem? Everything right over here. Again I have not written much topic so that you don't look, it does not look very big for you and you don't get demotivated. But all these concepts, again I have made a live playlist in my community series that is regarding day one to day five. So if you probably open this link, okay. So here you'll be able to see day one to day five. After day five, if I see this deep learning concept. So what I will do, I will open my YouTube channel and I'll write Krishnayak live deep learning, okay. So I will update those link over there. And here you have, right, so this is basically your live deep learning sessions, okay. So here you can probably see this day one to day five. This is basically the prerequisite, right. All the important things, how does forward propagation work? What is chain rule of derivatives? What exactly is optimizers? What exactly is loss function? What is forward propagation, backward propagation? The CNN I have actually implemented and shown in the practical way. So this link I will try to update it over here, right. So in basic deep learning concept, this is must. Because unless you don't understand that, the further topics will not be able to understand. This is the smartest way that I've actually created a roadmap where unnecessary jargons need not be added, okay. Then after you complete this, then we go to the advanced NLP concept. Now advanced NLP concept is nothing but day six to last video. Which one? If you probably click this link, here you'll be able to see six to entire tilt transformer. So here you can see day six, day seven. Here I've discussed about RNN. Here I've discussed about back propagation in RNN, LHTMRNN, word embedding, LHTM practical implementation, advanced LNM series, bidirectional LHTM, transformers, encoder, decoder. Everything is basically covered in all the specific videos. So if you are able to cover this from day six to probably 13th or 14th video, all these topics will be easily covered. If you are not able to find some topic, go and search for that topic with my name over there. I have a lot of videos. I have 1800 plus videos in my YouTube channel. When I've covered everything and this is what I've done from past three years, all the basics concepts have made strong so that you can clear the interview. There is no query that you cannot clear the interview guys. The kind of content that I've put in my YouTube channel is completely from free scratch, everything from basics so that you learn any advanced thing. It will be very much easy for you to crack the interview. So that is what my advanced NLP concept says where my main aim was to cover the transformer because after that, whenever you start your generative AI, that basically means most of your models are in the form of transformers or BERT, right? So here you have GPT-4, Mistral 7B. So here is where you probably start your journey. This is what is the prerequisite till here, right? And that is the reason I've created this prerequisite in this specific way. And it is simple. It's more about learn to the point, right? Don't waste your time much. Learn to the point, see some practical implementation because I don't think so this kind of practical implementation you will be doing in the industry also. But yes, in the interview, they may ask you now for those people who are directly developer, they can also jump in this particular topic, right? They can directly start from here because at the end of the day, they are very good at development, you know, who are full stack web developer who are working in the software engineering field, they can directly use these APIs and they can implement it. Now if I talk about some important things over here, right? Starting the journey towards generative AI. You need to really be very much open minded in probably doing a research on all these models, right? So Mistral 7b, Lama, Lama index, hugging face, open source libraries, Google Palm model and all, right? I've written over here because there are a lot of updates that are coming with respect to the specific models. And I'll tell you GPT-4 is must, hugging face is must, Lama, Mistral 7b, Mistral 7b has now recently come up with one amazing model. Again, we say it as a 87 cross B, right? Something like that. I'll be talking more about those models as we go ahead, right? And also try to see open source LNM models because with all this help of these models, you know, you can develop any business use cases that are specifically related to NLP, right? NLP, natural language processing, any use cases, chatbot to text summarization to documentation, anything, quiz, anything. So that is specifically required for the companies, you will be able to do this, right? And that is the reason why many companies are specifically using it. Large image models also you can use because all this large image models they'll be providing your diffusion models, they'll be providing your Dali, right? And based on that, you can do all further on top of it. But really, I'm focusing more on LLMs right now. So the first thing is OpenAI. It has amazing documentation link. Have already created videos, good playlist of videos over here, you can definitely look it out. And this documentation you really need to be good at. And the best thing about this documentation in OpenAI, it provides a good amazing things, right? OpenAI, start with this. Videos are given, you can definitely refer it. This year, I'm going to target LangChain like anything. LangChain, already if you go and see my YouTube playlist, they are on 10 to 12 videos. But LangChain is one amazing library that acts as a wrapper on top of OpenAI. It can also use hugging face. It has so many different functionalities to create all the LLM models, not only this. So LangChain also provides deployment techniques like LangServ, chain rest as rest APIs. This is nothing but it is entirely called as LangSmith. So you can probably see this is your LangChain application. It may be in Python, it may be in JavaScript. On top of that, you will be creating some template, you will be doing the deployment in the form of APIs by using this LangSmith. So going forward, I really want to probably see this entire tool and deployment techniques also and it is very much it is recently been announced, right? Why I like LangChain is that because it has so many different functionalities over here, right? Different functionalities from chatbots to prompts to modules to probably if you go and see right, what is LangServ will be releasing a hosted version of LangServ from one click deployment. Just imagine just one click deployment. All these things we are going to explore like anything as we go ahead, right? In LLMs, what exactly is unsync API, dissolve, prompting, most of the videos that I have already created, but every day I see something is getting added in this documentation, right? Over here only, if you probably see with respect to retrieval, right? In document loader, like which all documents will be able to load like CSV, file directory, HTML, JSON, markdown, PDF, document transformer, how do you split the documents and all, everything. But most of this everything will be combined in the form of a project in the end to end project where I do the deployment in an amazing way, right? All those things will basically be covered and here is a detailed video. After I get a good expertise on LangChain, I will also be starting with Chainlit. So Chainlit is another one documentation which looks very good over here, right? Good you will be able to do everything with the help of LangChain, Lama index, here also it is supported. You will also be able to do the deployment, right? Everything is there. You can do it in AWS, Azure, Google route, Replate, render, fly.io, hugging face spaces, okay? So once you probably cover this, right now in these two years you can probably target OpenAI and LangChain and Chainlit, okay? That is what I am actually going to do and based on this I will try to create a lot of videos, okay? LangChain, again you can interact with hugging face models, Lama, Mistral 7b, anything as such, whatever you want, okay? The next topic that you really need to focus is about vector databases and vector stores. Now vector database will play a very important role and again this will again be a part of LangChain itself because in LangChain it provides you functionalities. Some of the vector databases that I have already explored is like ChromaDB, FIAS. It is FIAS vector database is nothing but which makes use of Facebook AI similarity search library, right? So this is coming from Facebook. LandDB vector database based on the Lange data format. So there is a format which is called as Lange data set and again there you will be able to apply similarity search. Cassandra DB for storing vectors, Cassandra DB is also amazing, MongoDB is also amazing, right? At the end of the day, if you have any text you really want to convert that into vectors and since it is for the performance sake you really need to store it in some kind of vector database so that you can retrieve it and enjoy it. Then finally after doing this you have to probably do the deployment of LLM projects and this is what I am going to target. Within one month you will find all these videos in my YouTube channel, right? In AWS, Azure, LangSmith, LangSpa, HuggingFace, wherever you want to do the deployment. And finally guys if you really want to go ahead and check like how does, what is GenitiveAI, whether GenitiveAI is there for nano. I have given the course link over here, okay? This is a free community course where everybody can probably apply for it. You will find all the videos, materials and all and it is live series. Right now we are in day 5, day 6. So please go ahead and check it out, it is completely for free. See whether GenitiveAI is for you or not. And I hope if you are already in the data field I feel you really need to go towards GenitiveAI, right? At the end of the day. Because for the interview sake, yes, basic questions will be asked. But when you implement things in the production level, this all will be very much handy. And this is what is my main aim in 2024. I hope you like this particular video. Yes, please go ahead. Right now this is in private, I will make it public. So let me go ahead and make it public. So I will change it to public so that you can also access it. Make this repository public. And now one final thing is that I will also update this specific link of deep learning. So I hope you like this particular video. This was it from my side. I will see you all in the next video. Have a great day. Thank you and all. Take care. Bye bye.\"\"\"\n",
        "\n",
        "# Get the summary\n",
        "final_summary = summarize_text(text)\n",
        "print(final_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N4ouewx488C",
        "outputId": "9447ae09-8444-40a9-a613-b40f1354bff8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Krushnayak: In 2023, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects. In 2024, I'm going to completely focus most of my, if I say 100% from 100%, I'll focus 60 to 70% in generative AI and 30% with respect to MLOps platform.\n",
            "\n",
            "In this video, I've created an amazing roadmap to learn generative AI in 2024. This will be specifically for two kinds of roles, which I'm actually going to discuss. And this roadmap, trust me, it has some prerequisites. If you just cover those prerequisites, that will be more than sufficient to start with Generative AI.\n",
            "\n",
            "After completing Python, you will basically be having the basic machine learning natural language processing. If you search for streamlet in my YouTube channel, you'll be able to get those videos also. This is the one thing that I'm talking about this roadmap, I really want to make it for understanding how you can become better in generative AI in the field of LLM applications.\n",
            "\n",
            "Krishnayak: I've taken already natural language processing live session where I've covered in five days all these topics. So if I probably go ahead and open this particular video here from day one to day five, you'll be getting everything like word embedding, C bow, what is skip gram, word to beck. And this also includes practical implementation.\n",
            "\n",
            "I have 1800 plus videos in my YouTube channel. When I've covered everything and this is what I've done from past three years, all the basics concepts have made strong so that you can clear the interview. So here you have GPT-4, Mistral 7B. This is what is the prerequisite till here, right? And that is the reason I've created this prerequisite in this specific way. And it is simple. Don't waste your time much.\n",
            "\n",
            "LangChain is one amazing library that acts as a wrapper on top of OpenAI. It has so many different functionalities to create all the LLM models, not only this. LangChain also provides deployment techniques like LangServ, chain rest as rest APIs. Everything is there. You can do it in AWS, Azure, Google route, Replate, render, fly.io.\n",
            "\n",
            "The next topic that you really need to focus is about vector databases and vector stores. vector database will play a very important role and again this will again be a part of LangChain itself. Then finally after doing this you have to probably do the deployment of LLM projects and this is what I am going to target. Within one month you will find all these videos in my YouTube channel, right?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Load the BART model and tokenizer\n",
        "model_name = 'facebook/bart-large-cnn'\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "def chunk_text(text, max_tokens=700):\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    current_length = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = tokenizer.encode(sentence, add_special_tokens=False)\n",
        "        if current_length + len(tokens) < max_tokens:\n",
        "            current_chunk += \" \" + sentence\n",
        "            current_length += len(tokens)\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence\n",
        "            current_length = len(tokens)\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def summarize_chunk(chunk):\n",
        "    inputs = tokenizer.encode(chunk, return_tensors='pt', max_length=1024, truncation=True)\n",
        "    summary_ids = model.generate(inputs, max_length=250, min_length=80, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "def summarize_text(text):\n",
        "    chunks = chunk_text(text)\n",
        "    summarized_chunks = [summarize_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine summaries as paragraphs\n",
        "    combined_summary = \"\\n\\n\".join(summarized_chunks)\n",
        "    return combined_summary\n",
        "\n",
        "# Example text\n",
        "text = \"\"\"Hello all, my name is Krushnayak and welcome to my YouTube channel. So guys before the start of every new year, I usually plan that what all skill sets I really need to add in my bucket list so that I'll be able to teach you all. I will be also able to show you that how specifically it is used in industries. In 2023, you know, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects. I have covered a lot many MLops platform tools, you know, and I've shown each and everything, which was really beneficial for many people out there who really want to make successful career transition into the data science industry. And MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there. So many tools in generative AI have actually come frameworks, libraries and many more things. So MLops will still be there in 2024. But my main aim in 2023 was to understand all about different MLops platform and try to create videos, try to upgrade myself with respect to all those skill sets and provide those videos to you. This was very beneficial. Many people were able to make successful career transition. Now in 2024, I'm also going to focus. See in 2023 also from past three to four months, I'm really much focused in generative AI solving amazing use cases, trying to see multiple frameworks, trying to see multiple LLM models, how you can fine tune it, how you can probably use it in business use cases. And based on that, I'm also creating projects. But majorly in 2024, right, the weightage between MLops and generative AI, I will try to put my most of the weightage in understanding different, different frameworks, cloud platforms, techniques in business use cases in the field of generative AI. So in this video, like if you are also interested and obviously you can see the growth in generative area, how it is happening every other day, some new things are actually coming, right? Let it be models, let it be LLM models, the recent launch of Google Gemini. I know that Gemini did not provide you the right kind of demo video. But other than that, you have Mistral 7B, you have OpenAI, GPD for turbo, right? All these models are specifically coming. Now people are using this in creating amazing AI applications. And you can see there are a lot of startups from image to text, text to image. There are so many different things. I was just seeing one AI platform today, you know, it is basically called as Pickalabs. You just give a prompt and it will try to create an amazing video for you, right? And just imagine you don't even require a video editing any person over there, right? And this is super easy, right? When you probably see this kind of application. So 2024, I'm going to completely focus most of my, if I say 100% from 100%, I'm going to focus 60 to 70% in generative AI and 30% with respect to MLOps platform. And don't worry, every videos that I probably learn will be coming in the form of YouTube channel. But in this video, if you are also really interested to understand about generative AI, I've created an amazing roadmap to learn generative AI in 2024. And this will be specifically for two kinds of roles, which I'm actually going to discuss. And this roadmap, trust me, it has some prerequisites. I'm also going to provide you some videos over here, because if you just cover those prerequisites, that will be more than sufficient to start with generative AI. Yeah. And this is for all those people who are really interested to work in the data field, right? Data analytics field. If you're a developer, if you probably want to work into the generative AI, I think you don't even require this prerequisite. And I'll also call out that specific information over here in my GitHub. Once I probably show you the specific roadmap. So let me go ahead and let me share my screen. So this is the roadmap to learn generative AI. So here you can probably see everything is there. I've provided videos link, I have everything, the prerequisites that is actually required. Everything is mentioned over here. And please make sure that you fork this repository, keep a star on it, because 2024, I am going to really create a lot many things over here. It'll be quite amazing, right? Many, many things will be coming with respect to projects, with respect to frameworks, with respect to what are things I'm going to specifically cover in Lanch in everything, right? So let's start and let's understand this particular roadmap. Before you go ahead, please make sure that you hit like for this particular video will target at 2000 likes at least, you know, because this will be super beneficial because here you're going to get all the videos, all the materials, everything in front of you with respect to the prerequisites. Now I will talk about two different profiles over here. One profile is that if you want to get into the data analytics industry, and let's say you want to probably start if you're starting from scratch, okay, starting from scratch, or from past two years, you're also already in the data analytics field, you're learning about data science, what kind of upgradation you can basically do. The second type of people will be core developers, right? So in my company also, we have used generative AI, we are creating support systems, we are creating assignment, Q&A systems, many more things are there. Right now those developers are specifically creating and they don't have need to have all the knowledge with respect to some kind of prerequisites as such directly they can start with generative AI. So I will be talking about both of them step by step will try to understand. So the roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language. I will again prefer Python programming language because trust me any LLM models that is probably coming from hugging face to open AI to Mistral everywhere Python SDK is there, right? So Python SDK with the help of Python programming language, you will be able to access those API's, you'll be able to probably work on them, you will be able to probably implement any kind of applications. And not only that, you'll also be able to deploy because they are good cloud platforms that are specifically come with respect to that. Okay, so here, Python programming language, I have given this particular link, see, I've already created Python programming language in English in Hindi, we'll be able to probably find out all this particular videos. I've already shown you this particular videos, good videos, if you probably see there are millions and millions of views with respect to this all videos. Again at the end of the day, this will be super beneficial for everyone out there, right? And not only this Python, if you just want to also become a Python programmer, everything is covered from modular coding to inheritance to oops constant, everything is probably explained along with materials. So this is the first thing. Now here, in third and fourth, I have also added some frameworks playlist, right? Like what like Flask playlist, fast API tutorials and all, right? So these are frameworks, streamlet is one framework, different different frameworks you can specifically use, okay? It is up to you. See, I've created videos on streamlet also I've created videos on Gradio also, but I've just given two frameworks over here Flask and fast API to just give you an idea. If you search for streamlet in my YouTube channel, you'll be able to get those videos also. So Python is the first thing, okay? Usually if you are from another like other like core, if you are directly a developer, you have working in applications, you're creating like full stack web developer, you're having those kind of position. And let's say someone comes and tells you, okay, go ahead and apply this generative way. I think in our project, try to create a chat bot, try to create something. At that time, you don't require Python, whatever will be a core language like JavaScript or you can go ahead with that because that kind of SDK is also provided. But this is specifically with respect to the data field. Now coming to the next thing, see, over here, the roadmap that I'm talking about generative AI, this is with respect to LLM models, I'm not talking about large image models, okay? What I feel is that computer vision, large image models is also good. But the kind of kind of update, upgradation that are specifically happening is with respect to LLM models. This is the one thing that I'm talking about this roadmap, I really want to make it for understanding like how you can become better in generative AI in the field of LLM applications, okay, large language model. Whenever I say large language model, I'm basically talking about NLP. Okay? I am not exploring much in large image models because computer vision, I too don't have that much interest. So in my YouTube channel, so you'll be finding videos that I have not uploaded much with respect to computer vision, okay? But I'm really interested in NLP. So after completing Python, you will basically be having the basic machine learning natural language processing. Again, this is basically the prerequisites, okay? And here I've given, I've taken already natural language processing live session where I've covered in five days all these topics, YNLP, one-hot encoding, bag of words, TF-IDF, word to beck, average word to beck, and there are a lot many topics that I've actually covered, which you will be able to find over here from day one to day five. So if I probably go ahead and open this particular video here from day one to day five, you'll be getting everything like word embedding, C bow, what is skip gram, word to beck. This five video will be able to help you understand because see, this is a very good roadmap, a prerequisite, a short roadmap. I'm not going to make a very big roadmap because this concept is basically used so that you understand them. What is vectors? You know, how we convert text into a numerical variable. All these things will be important for your interview because in the interview, they'll not directly are generated way, I think. They'll first of all see how good your basics is, right? So considering this, here I could add more topics over here based on this day one to day five, but your task is as a prerequisite is to basically see this day one to day five. And this also includes practical implementation. Now the third day, third part is that you need to cover basic deep learning concepts. Now when I say basic deep learning concepts, this is something related to ANN, like how does a multilayer neural network work? What is perceptron? What is forward propagation, backward propagation, activation function, loss function optimizers? What is weight initialization techniques? What is vanishing gradient problem? Everything right over here. Again I have not written much topic so that you don't look, it does not look very big for you and you don't get demotivated. But all these concepts, again I have made a live playlist in my community series that is regarding day one to day five. So if you probably open this link, okay. So here you'll be able to see day one to day five. After day five, if I see this deep learning concept. So what I will do, I will open my YouTube channel and I'll write Krishnayak live deep learning, okay. So I will update those link over there. And here you have, right, so this is basically your live deep learning sessions, okay. So here you can probably see this day one to day five. This is basically the prerequisite, right. All the important things, how does forward propagation work? What is chain rule of derivatives? What exactly is optimizers? What exactly is loss function? What is forward propagation, backward propagation? The CNN I have actually implemented and shown in the practical way. So this link I will try to update it over here, right. So in basic deep learning concept, this is must. Because unless you don't understand that, the further topics will not be able to understand. This is the smartest way that I've actually created a roadmap where unnecessary jargons need not be added, okay. Then after you complete this, then we go to the advanced NLP concept. Now advanced NLP concept is nothing but day six to last video. Which one? If you probably click this link, here you'll be able to see six to entire tilt transformer. So here you can see day six, day seven. Here I've discussed about RNN. Here I've discussed about back propagation in RNN, LHTMRNN, word embedding, LHTM practical implementation, advanced LNM series, bidirectional LHTM, transformers, encoder, decoder. Everything is basically covered in all the specific videos. So if you are able to cover this from day six to probably 13th or 14th video, all these topics will be easily covered. If you are not able to find some topic, go and search for that topic with my name over there. I have a lot of videos. I have 1800 plus videos in my YouTube channel. When I've covered everything and this is what I've done from past three years, all the basics concepts have made strong so that you can clear the interview. There is no query that you cannot clear the interview guys. The kind of content that I've put in my YouTube channel is completely from free scratch, everything from basics so that you learn any advanced thing. It will be very much easy for you to crack the interview. So that is what my advanced NLP concept says where my main aim was to cover the transformer because after that, whenever you start your generative AI, that basically means most of your models are in the form of transformers or BERT, right? So here you have GPT-4, Mistral 7B. So here is where you probably start your journey. This is what is the prerequisite till here, right? And that is the reason I've created this prerequisite in this specific way. And it is simple. It's more about learn to the point, right? Don't waste your time much. Learn to the point, see some practical implementation because I don't think so this kind of practical implementation you will be doing in the industry also. But yes, in the interview, they may ask you now for those people who are directly developer, they can also jump in this particular topic, right? They can directly start from here because at the end of the day, they are very good at development, you know, who are full stack web developer who are working in the software engineering field, they can directly use these APIs and they can implement it. Now if I talk about some important things over here, right? Starting the journey towards generative AI. You need to really be very much open minded in probably doing a research on all these models, right? So Mistral 7b, Lama, Lama index, hugging face, open source libraries, Google Palm model and all, right? I've written over here because there are a lot of updates that are coming with respect to the specific models. And I'll tell you GPT-4 is must, hugging face is must, Lama, Mistral 7b, Mistral 7b has now recently come up with one amazing model. Again, we say it as a 87 cross B, right? Something like that. I'll be talking more about those models as we go ahead, right? And also try to see open source LNM models because with all this help of these models, you know, you can develop any business use cases that are specifically related to NLP, right? NLP, natural language processing, any use cases, chatbot to text summarization to documentation, anything, quiz, anything. So that is specifically required for the companies, you will be able to do this, right? And that is the reason why many companies are specifically using it. Large image models also you can use because all this large image models they'll be providing your diffusion models, they'll be providing your Dali, right? And based on that, you can do all further on top of it. But really, I'm focusing more on LLMs right now. So the first thing is OpenAI. It has amazing documentation link. Have already created videos, good playlist of videos over here, you can definitely look it out. And this documentation you really need to be good at. And the best thing about this documentation in OpenAI, it provides a good amazing things, right? OpenAI, start with this. Videos are given, you can definitely refer it. This year, I'm going to target LangChain like anything. LangChain, already if you go and see my YouTube playlist, they are on 10 to 12 videos. But LangChain is one amazing library that acts as a wrapper on top of OpenAI. It can also use hugging face. It has so many different functionalities to create all the LLM models, not only this. So LangChain also provides deployment techniques like LangServ, chain rest as rest APIs. This is nothing but it is entirely called as LangSmith. So you can probably see this is your LangChain application. It may be in Python, it may be in JavaScript. On top of that, you will be creating some template, you will be doing the deployment in the form of APIs by using this LangSmith. So going forward, I really want to probably see this entire tool and deployment techniques also and it is very much it is recently been announced, right? Why I like LangChain is that because it has so many different functionalities over here, right? Different functionalities from chatbots to prompts to modules to probably if you go and see right, what is LangServ will be releasing a hosted version of LangServ from one click deployment. Just imagine just one click deployment. All these things we are going to explore like anything as we go ahead, right? In LLMs, what exactly is unsync API, dissolve, prompting, most of the videos that I have already created, but every day I see something is getting added in this documentation, right? Over here only, if you probably see with respect to retrieval, right? In document loader, like which all documents will be able to load like CSV, file directory, HTML, JSON, markdown, PDF, document transformer, how do you split the documents and all, everything. But most of this everything will be combined in the form of a project in the end to end project where I do the deployment in an amazing way, right? All those things will basically be covered and here is a detailed video. After I get a good expertise on LangChain, I will also be starting with Chainlit. So Chainlit is another one documentation which looks very good over here, right? Good you will be able to do everything with the help of LangChain, Lama index, here also it is supported. You will also be able to do the deployment, right? Everything is there. You can do it in AWS, Azure, Google route, Replate, render, fly.io, hugging face spaces, okay? So once you probably cover this, right now in these two years you can probably target OpenAI and LangChain and Chainlit, okay? That is what I am actually going to do and based on this I will try to create a lot of videos, okay? LangChain, again you can interact with hugging face models, Lama, Mistral 7b, anything as such, whatever you want, okay? The next topic that you really need to focus is about vector databases and vector stores. Now vector database will play a very important role and again this will again be a part of LangChain itself because in LangChain it provides you functionalities. Some of the vector databases that I have already explored is like ChromaDB, FIAS. It is FIAS vector database is nothing but which makes use of Facebook AI similarity search library, right? So this is coming from Facebook. LandDB vector database based on the Lange data format. So there is a format which is called as Lange data set and again there you will be able to apply similarity search. Cassandra DB for storing vectors, Cassandra DB is also amazing, MongoDB is also amazing, right? At the end of the day, if you have any text you really want to convert that into vectors and since it is for the performance sake you really need to store it in some kind of vector database so that you can retrieve it and enjoy it. Then finally after doing this you have to probably do the deployment of LLM projects and this is what I am going to target. Within one month you will find all these videos in my YouTube channel, right? In AWS, Azure, LangSmith, LangSpa, HuggingFace, wherever you want to do the deployment. And finally guys if you really want to go ahead and check like how does, what is GenitiveAI, whether GenitiveAI is there for nano. I have given the course link over here, okay? This is a free community course where everybody can probably apply for it. You will find all the videos, materials and all and it is live series. Right now we are in day 5, day 6. So please go ahead and check it out, it is completely for free. See whether GenitiveAI is for you or not. And I hope if you are already in the data field I feel you really need to go towards GenitiveAI, right? At the end of the day. Because for the interview sake, yes, basic questions will be asked. But when you implement things in the production level, this all will be very much handy. And this is what is my main aim in 2024. I hope you like this particular video. Yes, please go ahead. Right now this is in private, I will make it public. So let me go ahead and make it public. So I will change it to public so that you can also access it. Make this repository public. And now one final thing is that I will also update this specific link of deep learning. So I hope you like this particular video. This was it from my side. I will see you all in the next video. Have a great day. Thank you and all. Take care. Bye bye.\"\"\"\n",
        "\n",
        "# Get the summary\n",
        "final_summary = summarize_text(text)\n",
        "print(final_summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSiUKXkn8n0O",
        "outputId": "36a324a7-a02c-4952-ac2c-2b8c795221de"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Krushnayak: In 2023, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects. In 2024, I'm going to completely focus most of my, if I say 100% from 100% in generative AI and 30% with respect to MLOps platform. And don't worry, every videos that I probably learn will be coming in the form of YouTube channel.\n",
            "\n",
            "In this video, I've created an amazing roadmap to learn generative AI in 2024. This will be specifically for two kinds of roles, which I'm actually going to discuss. And this roadmap, trust me, it has some prerequisites. I'm also going to provide you some videos over here, because if you just cover those prerequisites, that will be more than sufficient to start with Generative AI.\n",
            "\n",
            "After completing Python, you will basically be having the basic machine learning natural language processing. If you search for streamlet in my YouTube channel, you'll be able to get those videos also. This is the one thing that I'm talking about this roadmap, I really want to make it for understanding like how you can become better in generative AI in the field of LLM applications, okay?\n",
            "\n",
            "Krishnayak: I've taken already natural language processing live session where I've covered in five days all these topics. So if I probably go ahead and open this particular video here from day one to day five, you'll be getting everything like word embedding, C bow, what is skip gram, word to beck. This five video will be able to help you understand because see, this is a very good roadmap, a prerequisite, a short roadmap.\n",
            "\n",
            "I have 1800 plus videos in my YouTube channel. When I've covered everything and this is what I've done from past three years, all the basics concepts have made strong so that you can clear the interview. So here you have GPT-4, Mistral 7B. This is what is the prerequisite till here, right? And that is the reason I've created this prerequisite in this specific way. And it is simple. It's more about learn to the point. Don't waste your time much.\n",
            "\n",
            "LangChain is one amazing library that acts as a wrapper on top of OpenAI. It has so many different functionalities to create all the LLM models, not only this. LangChain also provides deployment techniques like LangServ, chain rest as rest APIs. Everything is there. You can do it in AWS, Azure, Google route, Replate, render, fly.io, hugging face spaces.\n",
            "\n",
            "The next topic that you really need to focus is about vector databases and vector stores. vector database will play a very important role and again this will again be a part of LangChain itself. Then finally after doing this you have to probably do the deployment of LLM projects. And this is what I am going to target. Within one month you will find all these videos in my YouTube channel, right?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#summarizing using key points etc\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import re\n",
        "\n",
        "# Initialize model and tokenizer\n",
        "model_name = 'facebook/bart-large-cnn'\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "def chunk_text(text, max_tokens=512):\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    current_length = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = tokenizer.encode(sentence, add_special_tokens=False)\n",
        "        if current_length + len(tokens) < max_tokens:\n",
        "            current_chunk += \" \" + sentence\n",
        "            current_length += len(tokens)\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence\n",
        "            current_length = len(tokens)\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def summarize_chunk(chunk):\n",
        "    inputs = tokenizer.encode(chunk, return_tensors='pt', max_length=1024, truncation=True)\n",
        "    summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "def extract_key_points(text):\n",
        "    # Simple key point extraction based on sentence structure and importance\n",
        "    sentences = sent_tokenize(text)\n",
        "    key_points = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        # Example heuristic: consider sentences with certain keywords or length\n",
        "        if len(sentence.split()) > 10 and ('.' in sentence or ':' in sentence):\n",
        "            key_points.append(sentence)\n",
        "\n",
        "    return key_points\n",
        "\n",
        "def postprocess_summary(summary):\n",
        "    # Remove extra whitespace\n",
        "    summary = ' '.join(summary.split())\n",
        "    return summary\n",
        "\n",
        "def summarize_text_with_key_points(text):\n",
        "    chunks = chunk_text(text)\n",
        "    summarized_chunks = [summarize_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine summaries\n",
        "    combined_summary = \" \".join(summarized_chunks)\n",
        "    combined_summary = postprocess_summary(combined_summary)\n",
        "\n",
        "    # Extract key points from the combined summary\n",
        "    key_points = extract_key_points(combined_summary)\n",
        "\n",
        "    # Create a final summary\n",
        "    final_summary = summarize_chunk(combined_summary)\n",
        "    final_summary = postprocess_summary(final_summary)\n",
        "\n",
        "    return {\n",
        "        'final_summary': final_summary,\n",
        "        'key_points': key_points\n",
        "    }\n",
        "\n",
        "# Example text\n",
        "text = \"\"\"Hello all, my name is Krushnayak and welcome to my YouTube channel. So guys before the start of every new year, I usually plan that what all skill sets I really need to add in my bucket list so that I'll be able to teach you all. I will be also able to show you that how specifically it is used in industries. In 2023, you know, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects. I have covered a lot many MLops platform tools, you know, and I've shown each and everything, which was really beneficial for many people out there who really want to make successful career transition into the data science industry. And MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there. So many tools in generative AI have actually come frameworks, libraries and many more things. So MLops will still be there in 2024. But my main aim in 2023 was to understand all about different MLops platform and try to create videos, try to upgrade myself with respect to all those skill sets and provide those videos to you. This was very beneficial. Many people were able to make successful career transition. Now in 2024, I'm also going to focus. See in 2023 also from past three to four months, I'm really much focused in generative AI solving amazing use cases, trying to see multiple frameworks, trying to see multiple LLM models, how you can fine tune it, how you can probably use it in business use cases. And based on that, I'm also creating projects. But majorly in 2024, right, the weightage between MLops and generative AI, I will try to put my most of the weightage in understanding different, different frameworks, cloud platforms, techniques in business use cases in the field of generative AI. So in this video, like if you are also interested and obviously you can see the growth in generative area, how it is happening every other day, some new things are actually coming, right? Let it be models, let it be LLM models, the recent launch of Google Gemini. I know that Gemini did not provide you the right kind of demo video. But other than that, you have Mistral 7B, you have OpenAI, GPD for turbo, right? All these models are specifically coming. Now people are using this in creating amazing AI applications. And you can see there are a lot of startups from image to text, text to image. There are so many different things. I was just seeing one AI platform today, you know, it is basically called as Pickalabs. You just give a prompt and it will try to create an amazing video for you, right? And just imagine you don't even require a video editing any person over there, right? And this is super easy, right? When you probably see this kind of application. So 2024, I'm going to completely focus most of my, if I say 100% from 100%, I'm going to focus 60 to 70% in generative AI and 30% with respect to MLOps platform. And don't worry, every videos that I probably learn will be coming in the form of YouTube channel. But in this video, if you are also really interested to understand about generative AI, I've created an amazing roadmap to learn generative AI in 2024. And this will be specifically for two kinds of roles, which I'm actually going to discuss. And this roadmap, trust me, it has some prerequisites. I'm also going to provide you some videos over here, because if you just cover those prerequisites, that will be more than sufficient to start with generative AI. Yeah. And this is for all those people who are really interested to work in the data field, right? Data analytics field. If you're a developer, if you probably want to work into the generative AI, I think you don't even require this prerequisite. And I'll also call out that specific information over here in my GitHub. Once I probably show you the specific roadmap. So let me go ahead and let me share my screen. So this is the roadmap to learn generative AI. So here you can probably see everything is there. I've provided videos link, I have everything, the prerequisites that is actually required. Everything is mentioned over here. And please make sure that you fork this repository, keep a star on it, because 2024, I am going to really create a lot many things over here. It'll be quite amazing, right? Many, many things will be coming with respect to projects, with respect to frameworks, with respect to what are things I'm going to specifically cover in Lanch in everything, right? So let's start and let's understand this particular roadmap. Before you go ahead, please make sure that you hit like for this particular video will target at 2000 likes at least, you know, because this will be super beneficial because here you're going to get all the videos, all the materials, everything in front of you with respect to the prerequisites. Now I will talk about two different profiles over here. One profile is that if you want to get into the data analytics industry, and let's say you want to probably start if you're starting from scratch, okay, starting from scratch, or from past two years, you're also already in the data analytics field, you're learning about data science, what kind of upgradation you can basically do. The second type of people will be core developers, right? So in my company also, we have used generative AI, we are creating support systems, we are creating assignment, Q&A systems, many more things are there. Right now those developers are specifically creating and they don't have need to have all the knowledge with respect to some kind of prerequisites as such directly they can start with generative AI. So I will be talking about both of them step by step will try to understand. So the roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language. I will again prefer Python programming language because trust me any LLM models that is probably coming from hugging face to open AI to Mistral everywhere Python SDK is there, right? So Python SDK with the help of Python programming language, you will be able to access those API's, you'll be able to probably work on them, you will be able to probably implement any kind of applications. And not only that, you'll also be able to deploy because they are good cloud platforms that are specifically come with respect to that. Okay, so here, Python programming language, I have given this particular link, see, I've already created Python programming languages playlist for you. You can go ahead and you can check it out. This is a basic prerequisite. Even if you know, you can just refresh your knowledge. It's just some basic knowledge that is actually required. The second thing, let's say if you have a good knowledge of Python, okay, then you can skip this. But again, if you don't have knowledge with respect to Python, the basic concept of Python programming language, you need to understand and then you can start with the second step. The second step will be to learn about the machine learning fundamentals. Okay. And again, I have given a link for this and you can learn about all these machine learning fundamentals, right? Like understanding supervised learning, supervised learning, all those concepts, different algorithms, which are available, how to build models, how to evaluate models, all those things you need to understand with respect to machine learning fundamentals. Then you move to step three. So here I have given all the machine learning fundamentals, everything. Now you can probably see this. You need to understand some machine learning fundamentals. And these are the things that you need to understand. Once you are good with Python, once you are good with machine learning fundamentals, you need to understand deep learning fundamentals. Okay. The deep learning fundamentals will be covering something like neural networks, CNN, RNN, sequence models, attention, transformers, right? Different activation functions, all those things, right? And once you're done with these, let's say you have a good knowledge about deep learning fundamentals, right? The next step will be to understand the generative AI. This is very important. So in generative AI, you have different types of models that are specifically available. I'll be covering most of the part over here, specifically that you need to focus with respect to each and every model. Okay. For example, I'll talk about some specific models. Let's say there is a model called as GPT-3, or you have something like chat GPT-3. You have GPT-4, you have Mistral 7B, you have Polyglot, you have Gemini. So all these are specifically coming, right? So you need to understand the generative AI basics. Once you understand the basics of generative AI, the next step will be to understand each and every framework that is available, like transformers from Hugging Face. You have LLMs from different platforms. And again, I have mentioned those links, how you can probably access it. Once you understand the frameworks and libraries, you need to understand the business use cases, right? For example, how can you use it in question answering? How can you use it in summarization? How can you use it in text generation? How can you use it in chatbots, right? There are different use cases which are available. And you need to have good knowledge of each and every use case, right? And then once you're good with business use cases, the last step will be to try to implement your projects. And I have mentioned these links over here. There are different links. Try to understand those particular implementations, try to build your projects, and then try to deploy it. And then you'll be good to go. Right? So this is the roadmap that is required. Now, if you're a core developer, okay, if you're a core developer, and if you want to get into the generative AI, there is no need to get into Python programming language or machine learning fundamentals. And you can start with the deep learning fundamentals, understanding generative AI basics, understanding different frameworks, business use cases, and implementing projects directly. Right? So this is the roadmap with respect to this. And in this particular GitHub repository, I have covered each and every detail. Please make sure that you hit like, make sure you fork the repository and keep a star on it. Also, subscribe to my YouTube channel so that you can get all the latest updates. And make sure that you hit that bell icon so that you'll be notified whenever I upload any new video. So with this, have a good day and happy learning.\"\"\"\n",
        "\n",
        "# Generate summary with key points\n",
        "result = summarize_text_with_key_points(text)\n",
        "\n",
        "print(\"Final Summary:\")\n",
        "print(result['final_summary'])\n",
        "print(\"\\nKey Points:\")\n",
        "for point in result['key_points']:\n",
        "    print(f\"- {point}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XRb_pmTFn0Z",
        "outputId": "c055335a-4706-44c4-ec81-27c97c11972c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Summary:\n",
            "In 2023, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects. MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there.\n",
            "\n",
            "Key Points:\n",
            "- In 2023, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects.\n",
            "- MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there.\n",
            "- And you can see there are a lot of startups from image to text, text to image.\n",
            "- I was just seeing one AI platform today, you know, it is basically called as Pickalabs.\n",
            "- The roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language.\n",
            "- If you have a good knowledge of Python, okay, then you can skip this.\n",
            "- But again, if you don't have knowledge with respect to Python, the basic concept of Python programming language, you need to understand.\n",
            "- The second step will be to learn about the machine learning fundamentals.\n",
            "- And once you're done with these, let's say you have a good knowledge about deep learning, the next step is to understand the generative AI.\n",
            "- There is no need to get into Python programming language or machine learning fundamentals.\n",
            "- You can start with the deep learning fundamentals, understanding generative AI basics, understanding different frameworks, business use cases, and implementing projects directly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import re\n",
        "\n",
        "# Initialize model and tokenizer\n",
        "model_name = 'facebook/bart-large-cnn'\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "def chunk_text(text, max_tokens=512):\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    current_length = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = tokenizer.encode(sentence, add_special_tokens=False)\n",
        "        if current_length + len(tokens) < max_tokens:\n",
        "            current_chunk += \" \" + sentence\n",
        "            current_length += len(tokens)\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence\n",
        "            current_length = len(tokens)\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def summarize_chunk(chunk):\n",
        "    inputs = tokenizer.encode(chunk, return_tensors='pt', max_length=1024, truncation=True)\n",
        "    summary_ids = model.generate(inputs, max_length=250, min_length=60, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "def extract_key_points(text):\n",
        "    # Simple key point extraction based on sentence structure and importance\n",
        "    sentences = sent_tokenize(text)\n",
        "    key_points = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        # Example heuristic: consider sentences with certain keywords or length\n",
        "        if len(sentence.split()) > 10 and ('.' in sentence or ':' in sentence):\n",
        "            key_points.append(sentence)\n",
        "\n",
        "    return key_points\n",
        "\n",
        "def postprocess_summary(summary):\n",
        "    # Remove extra whitespace\n",
        "    summary = ' '.join(summary.split())\n",
        "    return summary\n",
        "\n",
        "def summarize_text_with_key_points(text):\n",
        "    chunks = chunk_text(text)\n",
        "    combined_summary = \"\"\n",
        "\n",
        "    for idx, chunk in enumerate(chunks):\n",
        "        summary = summarize_chunk(chunk)\n",
        "        summary = postprocess_summary(summary)\n",
        "        print(f\"Summary {idx + 1}:\")\n",
        "        print(summary)\n",
        "        print()\n",
        "        combined_summary += \" \" + summary\n",
        "\n",
        "    # Extract key points from the combined summary\n",
        "    key_points = extract_key_points(combined_summary)\n",
        "\n",
        "    return {\n",
        "        'key_points': key_points\n",
        "    }\n",
        "\n",
        "# Example text (you can replace this with your text input)\n",
        "text = \"\"\"Hello all, my name is Krushnayak and welcome to my YouTube channel. So guys before the start of every new year, I usually plan that what all skill sets I really need to add in my bucket list so that I'll be able to teach you all. I will be also able to show you that how specifically it is used in industries. In 2023, you know, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects. I have covered a lot many MLops platform tools, you know, and I've shown each and everything, which was really beneficial for many people out there who really want to make successful career transition into the data science industry. And MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there. So many tools in generative AI have actually come frameworks, libraries and many more things. So MLops will still be there in 2024. But my main aim in 2023 was to understand all about different MLops platform and try to create videos, try to upgrade myself with respect to all those skill sets and provide those videos to you. This was very beneficial. Many people were able to make successful career transition. Now in 2024, I'm also going to focus. See in 2023 also from past three to four months, I'm really much focused in generative AI solving amazing use cases, trying to see multiple frameworks, trying to see multiple LLM models, how you can fine tune it, how you can probably use it in business use cases. And based on that, I'm also creating projects. But majorly in 2024, right, the weightage between MLops and generative AI, I will try to put my most of the weightage in understanding different, different frameworks, cloud platforms, techniques in business use cases in the field of generative AI. So in this video, like if you are also interested and obviously you can see the growth in generative area, how it is happening every other day, some new things are actually coming, right? Let it be models, let it be LLM models, the recent launch of Google Gemini. I know that Gemini did not provide you the right kind of demo video. But other than that, you have Mistral 7B, you have OpenAI, GPD for turbo, right? All these models are specifically coming. Now people are using this in creating amazing AI applications. And you can see there are a lot of startups from image to text, text to image. There are so many different things. I was just seeing one AI platform today, you know, it is basically called as Pickalabs. You just give a prompt and it will try to create an amazing video for you, right? And just imagine you don't even require a video editing any person over there, right? And this is super easy, right? When you probably see this kind of application. So 2024, I'm going to completely focus most of my, if I say 100% from 100%, I'm going to focus 60 to 70% in generative AI and 30% with respect to MLOps platform. And don't worry, every videos that I probably learn will be coming in the form of YouTube channel. But in this video, if you are also really interested to understand about generative AI, I've created an amazing roadmap to learn generative AI in 2024. And this will be specifically for two kinds of roles, which I'm actually going to discuss. And this roadmap, trust me, it has some prerequisites. I'm also going to provide you some videos over here, because if you just cover those prerequisites, that will be more than sufficient to start with generative AI. Yeah. And this is for all those people who are really interested to work in the data field, right? Data analytics field. If you're a developer, if you probably want to work into the generative AI, I think you don't even require this prerequisite. And I'll also call out that specific information over here in my GitHub. Once I probably show you the specific roadmap. So let me go ahead and let me share my screen. So this is the roadmap to learn generative AI. So here you can probably see everything is there. I've provided videos link, I have everything, the prerequisites that is actually required. Everything is mentioned over here. And please make sure that you fork this repository, keep a star on it, because 2024, I am going to really create a lot many things over here. It'll be quite amazing, right? Many, many things will be coming with respect to projects, with respect to frameworks, with respect to what are things I'm going to specifically cover in Lanch in everything, right? So let's start and let's understand this particular roadmap. Before you go ahead, please make sure that you hit like for this particular video will target at 2000 likes at least, you know, because this will be super beneficial because here you're going to get all the videos, all the materials, everything in front of you with respect to the prerequisites. Now I will talk about two different profiles over here. One profile is that if you want to get into the data analytics industry, and let's say you want to probably start if you're starting from scratch, okay, starting from scratch, or from past two years, you're also already in the data analytics field, you're learning about data science, what kind of upgradation you can basically do. The second type of people will be core developers, right? So in my company also, we have used generative AI, we are creating support systems, we are creating assignment, Q&A systems, many more things are there. Right now those developers are specifically creating and they don't have need to have all the knowledge with respect to some kind of prerequisites as such directly they can start with generative AI. So I will be talking about both of them step by step will try to understand. So the roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language. I will again prefer Python programming language because trust me any LLM models that is probably coming from hugging face to open AI to Mistral everywhere Python SDK is there, right? So Python SDK with the help of Python programming language, you will be able to access those API's, you'll be able to probably work on them, you will be able to probably implement any kind of applications. And not only that, you'll also be able to deploy because they are good cloud platforms that are specifically come with respect to that. Okay, so here, Python programming language, I have given this particular link, see, I've already created Python programming languages playlist for you. You can go ahead and you can check it out. This is a basic prerequisite. Even if you know, you can just refresh your knowledge. It's just some basic knowledge that is actually required. The second thing, let's say if you have a good knowledge of Python, okay, then you can skip this. But again, if you don't have knowledge with respect to Python, the basic concept of Python programming language, you need to understand and then you can start with the second step. The second step will be to learn about the machine learning fundamentals. Okay. And again, I have given a link for this and you can learn about all these machine learning fundamentals, right? Like understanding supervised learning, supervised learning, all those concepts, different algorithms, which are available, how to build models, how to evaluate models, all those things you need to understand with respect to machine learning fundamentals. Then you move to step three. So here I have given all the machine learning fundamentals, everything. Now you can probably see this. You need to understand some machine learning fundamentals. And these are the things that you need to understand. Once you are good with Python, once you are good with machine learning fundamentals, you need to understand deep learning fundamentals. Okay. The deep learning fundamentals will be covering something like neural networks, CNN, RNN, sequence models, attention, transformers, right? Different activation functions, all those things, right? And once you're done with these, let's say you have a good knowledge about deep learning fundamentals, right? The next step will be to understand the generative AI. This is very important. So in generative AI, you have different types of models that are specifically available. I'll be covering most of the part over here, specifically that you need to focus with respect to each and every model. Okay. For example, I'll talk about some specific models. Let's say there is a model called as GPT-3, or you have something like chat GPT-3. You have GPT-4, you have Mistral 7B, you have Polyglot, you have Gemini. So all these are specifically coming, right? So you need to understand the generative AI basics. Once you understand the basics of generative AI, the next step will be to understand each and every framework that is available, like transformers from Hugging Face. You have LLMs from different platforms. And again, I have mentioned those links, how you can probably access it. Once you understand the frameworks and libraries, you need to understand the business use cases, right? For example, how can you use it in question answering? How can you use it in summarization? How can you use it in text generation? How can you use it in chatbots, right? There are different use cases which are available. And you need to have good knowledge of each and every use case, right? And then once you're good with business use cases, the last step will be to try to implement your projects. And I have mentioned these links over here. There are different links. Try to understand those particular implementations, try to build your projects, and then try to deploy it. And then you'll be good to go. Right? So this is the roadmap that is required. Now, if you're a core developer, okay, if you're a core developer, and if you want to get into the generative AI, there is no need to get into Python programming language or machine learning fundamentals. And you can start with the deep learning fundamentals, understanding generative AI basics, understanding different frameworks, business use cases, and implementing projects directly. Right? So this is the roadmap with respect to this. And in this particular GitHub repository, I have covered each and every detail. Please make sure that you hit like, make sure you fork the repository and keep a star on it. Also, subscribe to my YouTube channel so that you can get all the latest updates. And make sure that you hit that bell icon so that you'll be notified whenever I upload any new video. So with this, have a good day and happy learning.\"\"\"\n",
        "\n",
        "# Generate summary with key points\n",
        "result = summarize_text_with_key_points(text)\n",
        "\n",
        "print(\"Key Points:\")\n",
        "for point in result['key_points']:\n",
        "    print(f\"- {point}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3YLT1ryGoDn",
        "outputId": "58f784f0-33cb-4131-e690-e3f3d605c69f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary 1:\n",
            "In 2023, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects. MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there.\n",
            "\n",
            "Summary 2:\n",
            "All these models are specifically coming. Now people are using this in creating amazing AI applications. And you can see there are a lot of startups from image to text, text to image. There are so many different things. I was just seeing one AI platform today, you know, it is basically called as Pickalabs. You just give a prompt and it will try to create an amazing video for you, right? And just imagine you don't even require a video editing any person over there, right?\"\n",
            "\n",
            "Summary 3:\n",
            "The roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language. The second thing, let's say if you have a good knowledge of Python, okay, then you can skip this. But again, if you don't have knowledge with respect to Python, the basic concept of Python programming language, you need to understand.\n",
            "\n",
            "Summary 4:\n",
            "The second step will be to learn about the machine learning fundamentals. The deep learning fundamentals will be covering something like neural networks, CNN, RNN, sequence models, attention, transformers, all those things, right? And once you're done with these, let's say you have a good knowledge about deep learning, the next step is to understand the generative AI.\n",
            "\n",
            "Summary 5:\n",
            "There is no need to get into Python programming language or machine learning fundamentals. You can start with the deep learning fundamentals, understanding generative AI basics, understanding different frameworks, business use cases, and implementing projects directly. So this is the roadmap with respect to this. And in this particular GitHub repository, I have covered each and every detail.\n",
            "\n",
            "Key Points:\n",
            "-  In 2023, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects.\n",
            "- MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there.\n",
            "- And you can see there are a lot of startups from image to text, text to image.\n",
            "- I was just seeing one AI platform today, you know, it is basically called as Pickalabs.\n",
            "- The roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language.\n",
            "- The second thing, let's say if you have a good knowledge of Python, okay, then you can skip this.\n",
            "- But again, if you don't have knowledge with respect to Python, the basic concept of Python programming language, you need to understand.\n",
            "- The second step will be to learn about the machine learning fundamentals.\n",
            "- And once you're done with these, let's say you have a good knowledge about deep learning, the next step is to understand the generative AI.\n",
            "- There is no need to get into Python programming language or machine learning fundamentals.\n",
            "- You can start with the deep learning fundamentals, understanding generative AI basics, understanding different frameworks, business use cases, and implementing projects directly.\n",
            "- And in this particular GitHub repository, I have covered each and every detail.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### best model trial 1\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Load the BART model and tokenizer\n",
        "model_name = 'facebook/bart-large-cnn'\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "def chunk_text(text, max_tokens=512):\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    current_length = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = tokenizer.encode(sentence, add_special_tokens=False)\n",
        "        if current_length + len(tokens) < max_tokens:\n",
        "            current_chunk += \" \" + sentence\n",
        "            current_length += len(tokens)\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence\n",
        "            current_length = len(tokens)\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def summarize_chunk(chunk):\n",
        "    inputs = tokenizer.encode(chunk, return_tensors='pt', max_length=1024, truncation=True)\n",
        "    summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "def extract_key_points(text):\n",
        "    # Simple key point extraction based on sentence structure and importance\n",
        "    sentences = sent_tokenize(text)\n",
        "    key_points = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        # Example heuristic: consider sentences with certain keywords or length\n",
        "        if len(sentence.split()) > 10 and ('.' in sentence or ':' in sentence):\n",
        "            key_points.append(sentence)\n",
        "\n",
        "    return key_points\n",
        "\n",
        "def summarize_text(text):\n",
        "    chunks = chunk_text(text)\n",
        "    summarized_chunks = [summarize_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine summaries as paragraphs\n",
        "    combined_summary = \"\\n\\n\".join(summarized_chunks)\n",
        "\n",
        "    # Extract key points from the combined summary\n",
        "    key_points = extract_key_points(combined_summary)\n",
        "\n",
        "    return {\n",
        "        'combined_summary': combined_summary,\n",
        "        'key_points': key_points\n",
        "    }\n",
        "\n",
        "# Example text\n",
        "text = \"\"\"Hello all, my name is Krushnayak and welcome to my YouTube channel. So guys before the start of every new year, I usually plan that what all skill sets I really need to add in my bucket list so that I'll be able to teach you all. I will be also able to show you that how specifically it is used in industries. In 2023, you know, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects. I have covered a lot many MLops platform tools, you know, and I've shown each and everything, which was really beneficial for many people out there who really want to make successful career transition into the data science industry. And MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there. So many tools in generative AI have actually come frameworks, libraries and many more things. So MLops will still be there in 2024. But my main aim in 2023 was to understand all about different MLops platform and try to create videos, try to upgrade myself with respect to all those skill sets and provide those videos to you. This was very beneficial. Many people were able to make successful career transition. Now in 2024, I'm also going to focus. See in 2023 also from past three to four months, I'm really much focused in generative AI solving amazing use cases, trying to see multiple frameworks, trying to see multiple LLM models, how you can fine tune it, how you can probably use it in business use cases. And based on that, I'm also creating projects. But majorly in 2024, right, the weightage between MLops and generative AI, I will try to put my most of the weightage in understanding different, different frameworks, cloud platforms, techniques in business use cases in the field of generative AI. So in this video, like if you are also interested and obviously you can see the growth in generative area, how it is happening every other day, some new things are actually coming, right? Let it be models, let it be LLM models, the recent launch of Google Gemini. I know that Gemini did not provide you the right kind of demo video. But other than that, you have Mistral 7B, you have OpenAI, GPD for turbo, right? All these models are specifically coming. Now people are using this in creating amazing AI applications. And you can see there are a lot of startups from image to text, text to image. There are so many different things. I was just seeing one AI platform today, you know, it is basically called as Pickalabs. You just give a prompt and it will try to create an amazing video for you, right? And just imagine you don't even require a video editing any person over there, right? And this is super easy, right? When you probably see this kind of application. So 2024, I'm going to completely focus most of my, if I say 100% from 100%, I'm going to focus 60 to 70% in generative AI and 30% with respect to MLOps platform. And don't worry, every videos that I probably learn will be coming in the form of YouTube channel. But in this video, if you are also really interested to understand about generative AI, I've created an amazing roadmap to learn generative AI in 2024. And this will be specifically for two kinds of roles, which I'm actually going to discuss. And this roadmap, trust me, it has some prerequisites. I'm also going to provide you some videos over here, because if you just cover those prerequisites, that will be more than sufficient to start with generative AI. Yeah. And this is for all those people who are really interested to work in the data field, right? Data analytics field. If you're a developer, if you probably want to work into the generative AI, I think you don't even require this prerequisite. And I'll also call out that specific information over here in my GitHub. Once I probably show you the specific roadmap. So let me go ahead and let me share my screen. So this is the roadmap to learn generative AI. So here you can probably see everything is there. I've provided videos link, I have everything, the prerequisites that is actually required. Everything is mentioned over here. And please make sure that you fork this repository, keep a star on it, because 2024, I am going to really create a lot many things over here. It'll be quite amazing, right? Many, many things will be coming with respect to projects, with respect to frameworks, with respect to what are things I'm going to specifically cover in Lanch in everything, right? So let's start and let's understand this particular roadmap. Before you go ahead, please make sure that you hit like for this particular video will target at 2000 likes at least, you know, because this will be super beneficial because here you're going to get all the videos, all the materials, everything in front of you with respect to the prerequisites. Now I will talk about two different profiles over here. One profile is that if you want to get into the data analytics industry, and let's say you want to probably start if you're starting from scratch, okay, starting from scratch, or from past two years, you're also already in the data analytics field, you're learning about data science, what kind of upgradation you can basically do. The second type of people will be core developers, right? So in my company also, we have used generative AI, we are creating support systems, we are creating assignment, Q&A systems, many more things are there. Right now those developers are specifically creating and they don't have need to have all the knowledge with respect to some kind of prerequisites as such directly they can start with generative AI. So I will be talking about both of them step by step will try to understand. So the roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language. I will again prefer Python programming language because trust me any LLM models that is probably coming from hugging face to open AI to Mistral everywhere Python SDK is there, right? So Python SDK with the help of Python programming language, you will be able to access those API's, you'll be able to probably work on them, you will be able to probably implement any kind of applications. And not only that, you'll also be able to deploy because they are good cloud platforms that are specifically come with respect to that. Okay, so here, Python programming language, I have given this particular link, see, I've already created Python programming languages playlist for you. You can go ahead and you can check it out. This is a basic prerequisite. Even if you know, you can just refresh your knowledge. It's just some basic knowledge that is actually required. The second thing, let's say if you have a good knowledge of Python, okay, then you can skip this. But again, if you don't have knowledge with respect to Python, the basic concept of Python programming language, you need to understand and then you can start with the second step. The second step will be to learn about the machine learning fundamentals. Okay. And again, I have given a link for this and you can learn about all these machine learning fundamentals, right? Like understanding supervised learning, supervised learning, all those concepts, different algorithms, which are available, how to build the models, how to understand the evaluation metrics, how to understand the performance metrics, everything. Then the next step, which is important, which you need to understand is NLP. Okay. And here I've also given a link, which will be very useful for you. Natural language processing fundamentals are really, really important to learn because any generative AI application that you're going to build will be using a lot of NLP algorithms. Right? So NLP is really important. Understanding how tokenization is done, how embeddings are done, right? Different kind of embedding techniques, vectorization techniques, everything is really important. The next step will be understanding deep learning fundamentals. Okay. And here, deep learning fundamentals will be the basis for your generative AI. For your generative AI applications, your deep learning will be using specifically transformers, LSTM, GRU and various other architectures, CNN. And these will be helpful for you. And again, I have provided specific link for this and these are the links which you can directly access and you can understand deep learning fundamentals. After you have these prerequisites and you have a good understanding, you can start with generative AI basics, right? Like understanding what is generative AI, what are some use cases, how exactly it is working, right? Generative AI with respect to text, generative AI with respect to images, right? Generative AI with respect to sound, music, everything, right? So this particular link will give you good understanding of what is generative AI, what are some of the applications that you can build, right? So that is really important to understand the basics of generative AI. After that, you need to understand specifically the different, different frameworks and libraries that are coming up in generative AI. Right? Like your LLM models, different kinds of models, different libraries, how you can use them. So this will be really helpful for you. The next step will be working on real-time projects and examples. Okay. And again, I've given a link for this and real-time projects will really help you to understand the practical aspect. Okay. And there are various different types of projects, right? So you will be able to implement a project and then you can learn from it. Right. So that's the reason I've given this link. So this is really helpful. And the last thing, okay. The last step will be to go ahead and create your own project, right? Once you understand all these fundamentals, try to create your own projects, right? For example, building chatbots, building question answering systems, building text summarization system, building, you know, generative AI for creating music, right? So these kinds of projects you can build, you can have a good showcase of your work. And this will really help you in your interviews, in your job interviews and even with respect to your resume. So this is how you can really learn generative AI in 2024. And please make sure that you follow all the steps. This is really helpful. And I hope that this is going to really add value to you. And once again, I'm going to mention this, please make sure you hit the like button. And this is really beneficial. Thank you. Bye bye. \"\"\"\n",
        "\n",
        "# Summarize the text and extract key points\n",
        "results = summarize_text(text)\n",
        "\n",
        "# Print the combined summary and key points\n",
        "print(\"Combined Summary:\")\n",
        "print(results['combined_summary'])\n",
        "print(\"\\nKey Points:\")\n",
        "for point in results['key_points']:\n",
        "    print(f\"- {point}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ft3egIXSJUsA",
        "outputId": "0381c4e8-7df5-4762-d179-6811e0ba4f23"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Summary:\n",
            "In 2023, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects. MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there.\n",
            "\n",
            "All these models are specifically coming. Now people are using this in creating amazing AI applications. And you can see there are a lot of startups from image to text, text to image. There are so many different things. I was just seeing one AI platform today, you know, it is basically called as Pickalabs. You just give a prompt and it will try to create an amazing video for you, right?\n",
            "\n",
            "The roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language. If you have a good knowledge of Python, okay, then you can skip this. But again, if you don't have knowledge with respect to Python, the basic concept of Python programming language, you need to understand.\n",
            "\n",
            "The second step will be to learn about the machine learning fundamentals. And again, I have given a link for this and you can learn about all these machine learning concepts. Then the next step, which is important, which you need to understand is NLP. And here, deep learning fundamentals will be the basis for your generative AI.\n",
            "\n",
            "And there are various different types of projects, right? So you will be able to implement a project and then you can learn from it. So this is how you can really learn generative AI in 2024. And please make sure that you follow all the steps. This is really helpful.\n",
            "\n",
            "Key Points:\n",
            "- In 2023, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects.\n",
            "- MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there.\n",
            "- And you can see there are a lot of startups from image to text, text to image.\n",
            "- I was just seeing one AI platform today, you know, it is basically called as Pickalabs.\n",
            "- The roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language.\n",
            "- If you have a good knowledge of Python, okay, then you can skip this.\n",
            "- But again, if you don't have knowledge with respect to Python, the basic concept of Python programming language, you need to understand.\n",
            "- The second step will be to learn about the machine learning fundamentals.\n",
            "- And again, I have given a link for this and you can learn about all these machine learning concepts.\n",
            "- Then the next step, which is important, which you need to understand is NLP.\n",
            "- And here, deep learning fundamentals will be the basis for your generative AI.\n",
            "- So you will be able to implement a project and then you can learn from it.\n",
            "- So this is how you can really learn generative AI in 2024.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### best model trial 2\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Load the BART model and tokenizer\n",
        "model_name = 'facebook/bart-large-cnn'\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "def chunk_text(text, max_tokens=500):\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    current_length = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = tokenizer.encode(sentence, add_special_tokens=False)\n",
        "        if current_length + len(tokens) < max_tokens:\n",
        "            current_chunk += \" \" + sentence\n",
        "            current_length += len(tokens)\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence\n",
        "            current_length = len(tokens)\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def summarize_chunk(chunk):\n",
        "    inputs = tokenizer.encode(chunk, return_tensors='pt', max_length=1024, truncation=True)\n",
        "    summary_ids = model.generate(inputs, max_length=250, min_length=60, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "def extract_key_points(text):\n",
        "    # Simple key point extraction based on sentence structure and importance\n",
        "    sentences = sent_tokenize(text)\n",
        "    key_points = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        # Example heuristic: consider sentences with certain keywords or length\n",
        "        if len(sentence.split()) > 10 and ('.' in sentence or ':' in sentence):\n",
        "            key_points.append(sentence)\n",
        "\n",
        "    return key_points\n",
        "\n",
        "def summarize_text(text):\n",
        "    chunks = chunk_text(text)\n",
        "    summarized_chunks = [summarize_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine summaries as paragraphs\n",
        "    combined_summary = \"\\n\\n\".join(summarized_chunks)\n",
        "\n",
        "    # Extract key points from the combined summary\n",
        "    key_points = extract_key_points(combined_summary)\n",
        "\n",
        "    return {\n",
        "        'combined_summary': combined_summary,\n",
        "        'key_points': key_points\n",
        "    }\n",
        "\n",
        "# Example text\n",
        "text = \"\"\"Hello all, my name is Krushnayak and welcome to my YouTube channel. So guys before the start of every new year, I usually plan that what all skill sets I really need to add in my bucket list so that I'll be able to teach you all. I will be also able to show you that how specifically it is used in industries. In 2023, you know, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects. I have covered a lot many MLops platform tools, you know, and I've shown each and everything, which was really beneficial for many people out there who really want to make successful career transition into the data science industry. And MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there. So many tools in generative AI have actually come frameworks, libraries and many more things. So MLops will still be there in 2024. But my main aim in 2023 was to understand all about different MLops platform and try to create videos, try to upgrade myself with respect to all those skill sets and provide those videos to you. This was very beneficial. Many people were able to make successful career transition. Now in 2024, I'm also going to focus. See in 2023 also from past three to four months, I'm really much focused in generative AI solving amazing use cases, trying to see multiple frameworks, trying to see multiple LLM models, how you can fine tune it, how you can probably use it in business use cases. And based on that, I'm also creating projects. But majorly in 2024, right, the weightage between MLops and generative AI, I will try to put my most of the weightage in understanding different, different frameworks, cloud platforms, techniques in business use cases in the field of generative AI. So in this video, like if you are also interested and obviously you can see the growth in generative area, how it is happening every other day, some new things are actually coming, right? Let it be models, let it be LLM models, the recent launch of Google Gemini. I know that Gemini did not provide you the right kind of demo video. But other than that, you have Mistral 7B, you have OpenAI, GPD for turbo, right? All these models are specifically coming. Now people are using this in creating amazing AI applications. And you can see there are a lot of startups from image to text, text to image. There are so many different things. I was just seeing one AI platform today, you know, it is basically called as Pickalabs. You just give a prompt and it will try to create an amazing video for you, right? And just imagine you don't even require a video editing any person over there, right? And this is super easy, right? When you probably see this kind of application. So 2024, I'm going to completely focus most of my, if I say 100% from 100%, I'm going to focus 60 to 70% in generative AI and 30% with respect to MLOps platform. And don't worry, every videos that I probably learn will be coming in the form of YouTube channel. But in this video, if you are also really interested to understand about generative AI, I've created an amazing roadmap to learn generative AI in 2024. And this will be specifically for two kinds of roles, which I'm actually going to discuss. And this roadmap, trust me, it has some prerequisites. I'm also going to provide you some videos over here, because if you just cover those prerequisites, that will be more than sufficient to start with generative AI. Yeah. And this is for all those people who are really interested to work in the data field, right? Data analytics field. If you're a developer, if you probably want to work into the generative AI, I think you don't even require this prerequisite. And I'll also call out that specific information over here in my GitHub. Once I probably show you the specific roadmap. So let me go ahead and let me share my screen. So this is the roadmap to learn generative AI. So here you can probably see everything is there. I've provided videos link, I have everything, the prerequisites that is actually required. Everything is mentioned over here. And please make sure that you fork this repository, keep a star on it, because 2024, I am going to really create a lot many things over here. It'll be quite amazing, right? Many, many things will be coming with respect to projects, with respect to frameworks, with respect to what are things I'm going to specifically cover in Lanch in everything, right? So let's start and let's understand this particular roadmap. Before you go ahead, please make sure that you hit like for this particular video will target at 2000 likes at least, you know, because this will be super beneficial because here you're going to get all the videos, all the materials, everything in front of you with respect to the prerequisites. Now I will talk about two different profiles over here. One profile is that if you want to get into the data analytics industry, and let's say you want to probably start if you're starting from scratch, okay, starting from scratch, or from past two years, you're also already in the data analytics field, you're learning about data science, what kind of upgradation you can basically do. The second type of people will be core developers, right? So in my company also, we have used generative AI, we are creating support systems, we are creating assignment, Q&A systems, many more things are there. Right now those developers are specifically creating and they don't have need to have all the knowledge with respect to some kind of prerequisites as such directly they can start with generative AI. So I will be talking about both of them step by step will try to understand. So the roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language. I will again prefer Python programming language because trust me any LLM models that is probably coming from hugging face to open AI to Mistral everywhere Python SDK is there, right? So Python SDK with the help of Python programming language, you will be able to access those API's, you'll be able to probably work on them, you will be able to probably implement any kind of applications. And not only that, you'll also be able to deploy because they are good cloud platforms that are specifically come with respect to that. Okay, so here, Python programming language, I have given this particular link, see, I've already created Python programming languages playlist for you. You can go ahead and you can check it out. This is a basic prerequisite. Even if you know, you can just refresh your knowledge. It's just some basic knowledge that is actually required. The second thing, let's say if you have a good knowledge of Python, okay, then you can skip this. But again, if you don't have knowledge with respect to Python, the basic concept of Python programming language, you need to understand and then you can start with the second step. The second step will be to learn about the machine learning fundamentals. Okay. And again, I have given a link for this and you can learn about all these machine learning fundamentals, right? Like understanding supervised learning, supervised learning, all those concepts, different algorithms, which are available, how to build the models, how to understand the evaluation metrics, how to understand the performance metrics, everything. Then the next step, which is important, which you need to understand is NLP. Okay. And here I've also given a link, which will be very useful for you. Natural language processing fundamentals are really, really important to learn because any generative AI application that you're going to build will be using a lot of NLP algorithms. Right? So NLP is really important. Understanding how tokenization is done, how embeddings are done, right? Different kind of embedding techniques, vectorization techniques, everything is really important. The next step will be understanding deep learning fundamentals. Okay. And here, deep learning fundamentals will be the basis for your generative AI. For your generative AI applications, your deep learning will be using specifically transformers, LSTM, GRU and various other architectures, CNN. And these will be helpful for you. And again, I have provided specific link for this and these are the links which you can directly access and you can understand deep learning fundamentals. After you have these prerequisites and you have a good understanding, you can start with generative AI basics, right? Like understanding what is generative AI, what are some use cases, how exactly it is working, right? Generative AI with respect to text, generative AI with respect to images, right? Generative AI with respect to sound, music, everything, right? So this particular link will give you good understanding of what is generative AI, what are some of the applications that you can build, right? So that is really important to understand the basics of generative AI. After that, you need to understand specifically the different, different frameworks and libraries that are coming up in generative AI. Right? Like your LLM models, different kinds of models, different libraries, how you can use them. So this will be really helpful for you. The next step will be working on real-time projects and examples. Okay. And again, I've given a link for this and real-time projects will really help you to understand the practical aspect. Okay. And there are various different types of projects, right? So you will be able to implement a project and then you can learn from it. Right. So that's the reason I've given this link. So this is really helpful. And the last thing, okay. The last step will be to go ahead and create your own project, right? Once you understand all these fundamentals, try to create your own projects, right? For example, building chatbots, building question answering systems, building text summarization system, building, you know, generative AI for creating music, right? So these kinds of projects you can build, you can have a good showcase of your work. And this will really help you in your interviews, in your job interviews and even with respect to your resume. So this is how you can really learn generative AI in 2024. And please make sure that you follow all the steps. This is really helpful. And I hope that this is going to really add value to you. And once again, I'm going to mention this, please make sure you hit the like button. And this is really beneficial. Thank you. Bye bye. \"\"\"\n",
        "\n",
        "# Summarize the text and extract key points\n",
        "results = summarize_text(text)\n",
        "\n",
        "# Print the combined summary and key points\n",
        "print(\"Combined Summary:\")\n",
        "print(results['combined_summary'])\n",
        "print(\"\\nKey Points:\")\n",
        "for point in results['key_points']:\n",
        "    print(f\"- {point}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQC_iZQtL-0x",
        "outputId": "76c53604-78a5-4b5b-9b33-f0583e44b23f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Summary:\n",
            "In 2023, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects. MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there.\n",
            "\n",
            "In 2024, I'm going to focus 60 to 70% in generative AI and 30% with respect to MLOps platform. And this will be specifically for two kinds of roles, which I'm actually going to discuss. I'm also going to provide you some videos over here, because if you just cover those prerequisites, that will be more than sufficient.\n",
            "\n",
            "Lanch: The roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language. Lanch: I will again prefer Python programming language because trust me any LLM models that is probably coming from hugging face to open AI to Mistral everywhere Python SDK is there.\n",
            "\n",
            "The second thing, let's say if you have a good knowledge of Python, okay, then you can skip this. But again, if you don't have knowledge with respect to Python, the basic concept of Python programming language, you need to understand. The second step will be to learn about the machine learning fundamentals. And here, deep learning fundamentals will be the basis for your generative AI.\n",
            "\n",
            "The next step will be working on real-time projects and examples. Once you understand all these fundamentals, try to create your own projects, right? For example, building chatbots, building question answering systems, building text summarization system. So these kinds of projects you can build, you can have a good showcase of your work. And this will really help you in your interviews.\n",
            "\n",
            "Key Points:\n",
            "- In 2023, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects.\n",
            "- MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there.\n",
            "- In 2024, I'm going to focus 60 to 70% in generative AI and 30% with respect to MLOps platform.\n",
            "- And this will be specifically for two kinds of roles, which I'm actually going to discuss.\n",
            "- I'm also going to provide you some videos over here, because if you just cover those prerequisites, that will be more than sufficient.\n",
            "- Lanch: The roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language.\n",
            "- Lanch: I will again prefer Python programming language because trust me any LLM models that is probably coming from hugging face to open AI to Mistral everywhere Python SDK is there.\n",
            "- The second thing, let's say if you have a good knowledge of Python, okay, then you can skip this.\n",
            "- But again, if you don't have knowledge with respect to Python, the basic concept of Python programming language, you need to understand.\n",
            "- The second step will be to learn about the machine learning fundamentals.\n",
            "- And here, deep learning fundamentals will be the basis for your generative AI.\n",
            "- The next step will be working on real-time projects and examples.\n",
            "- For example, building chatbots, building question answering systems, building text summarization system.\n",
            "- So these kinds of projects you can build, you can have a good showcase of your work.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence-transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1Kv41sYMe6-",
        "outputId": "db58a774-dfef-47bb-dd03-1368e8c9f392"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Using cached sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.42.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.6.20)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Using cached sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Installing collected packages: nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "Successfully installed nvidia-cudnn-cu12-8.9.2.26 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 sentence-transformers-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BERT-Based Sentence Embeddings for key text extraction\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, BertTokenizer, BertModel\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Load BART model and tokenizer\n",
        "model_name_bart = 'facebook/bart-large-cnn'\n",
        "tokenizer_bart = BartTokenizer.from_pretrained(model_name_bart)\n",
        "model_bart = BartForConditionalGeneration.from_pretrained(model_name_bart)\n",
        "\n",
        "# Load BERT model and tokenizer for key points extraction\n",
        "model_name_bert = 'bert-base-uncased'\n",
        "tokenizer_bert = BertTokenizer.from_pretrained(model_name_bert)\n",
        "model_bert = BertModel.from_pretrained(model_name_bert)\n",
        "\n",
        "def chunk_text(text, max_tokens=512):\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    current_length = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = tokenizer_bart.encode(sentence, add_special_tokens=False)\n",
        "        if current_length + len(tokens) < max_tokens:\n",
        "            current_chunk += \" \" + sentence\n",
        "            current_length += len(tokens)\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence\n",
        "            current_length = len(tokens)\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def summarize_chunk(chunk):\n",
        "    inputs = tokenizer_bart.encode(chunk, return_tensors='pt', max_length=1024, truncation=True)\n",
        "    summary_ids = model_bart.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = tokenizer_bart.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "def extract_key_points(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    embeddings = []\n",
        "\n",
        "    # Tokenize and encode sentences\n",
        "    for sentence in sentences:\n",
        "        inputs = tokenizer_bert(sentence, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "        with torch.no_grad():\n",
        "            outputs = model_bert(**inputs)\n",
        "            embeddings.append(outputs.last_hidden_state.mean(dim=1).squeeze().cpu())  # Move to CPU\n",
        "\n",
        "    # Compute pairwise cosine similarities\n",
        "    embeddings = torch.stack(embeddings)\n",
        "    cosine_sim = torch.nn.functional.cosine_similarity(embeddings.unsqueeze(0), embeddings.unsqueeze(1), dim=-1)\n",
        "\n",
        "    # Average similarity for each sentence\n",
        "    avg_similarities = cosine_sim.mean(dim=1)\n",
        "\n",
        "    # Sort sentences based on similarity scores\n",
        "    sorted_indices = np.argsort(avg_similarities.numpy())[::-1]  # Convert tensor to numpy array\n",
        "    key_points = [sentences[i] for i in sorted_indices[:5]]  # Get top 5 key points\n",
        "\n",
        "    return key_points\n",
        "\n",
        "def summarize_text(text):\n",
        "    chunks = chunk_text(text)\n",
        "    summarized_chunks = [summarize_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine summaries as paragraphs\n",
        "    combined_summary = \"\\n\\n\".join(summarized_chunks)\n",
        "\n",
        "    # Extract key points from the combined summary\n",
        "    key_points = extract_key_points(combined_summary)\n",
        "\n",
        "    return {\n",
        "        'combined_summary': combined_summary,\n",
        "        'key_points': key_points\n",
        "    }\n",
        "\n",
        "# Example text\n",
        "text = \"\"\"Hello all, my name is Krushnayak and welcome to my YouTube channel. So guys before the start of every new year, I usually plan that what all skill sets I really need to add in my bucket list so that I'll be able to teach you all. I will be also able to show you that how specifically it is used in industries. In 2023, you know, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects. I have covered a lot many MLops platform tools, you know, and I've shown each and everything, which was really beneficial for many people out there who really want to make successful career transition into the data science industry. And MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there. So many tools in generative AI have actually come frameworks, libraries and many more things. So MLops will still be there in 2024. But my main aim in 2023 was to understand all about different MLops platform and try to create videos, try to upgrade myself with respect to all those skill sets and provide those videos to you. This was very beneficial. Many people were able to make successful career transition. Now in 2024, I'm also going to focus. See in 2023 also from past three to four months, I'm really much focused in generative AI solving amazing use cases, trying to see multiple frameworks, trying to see multiple LLM models, how you can fine tune it, how you can probably use it in business use cases. And based on that, I'm also creating projects. But majorly in 2024, right, the weightage between MLops and generative AI, I will try to put my most of the weightage in understanding different, different frameworks, cloud platforms, techniques in business use cases in the field of generative AI. So in this video, like if you are also interested and obviously you can see the growth in generative area, how it is happening every other day, some new things are actually coming, right? Let it be models, let it be LLM models, the recent launch of Google Gemini. I know that Gemini did not provide you the right kind of demo video. But other than that, you have Mistral 7B, you have OpenAI, GPD for turbo, right? All these models are specifically coming. Now people are using this in creating amazing AI applications. And you can see there are a lot of startups from image to text, text to image. There are so many different things. I was just seeing one AI platform today, you know, it is basically called as Pickalabs. You just give a prompt and it will try to create an amazing video for you, right? And just imagine you don't even require a video editing any person over there, right? And this is super easy, right? When you probably see this kind of application. So 2024, I'm going to completely focus most of my, if I say 100% from 100%, I'm going to focus 60 to 70% in generative AI and 30% with respect to MLOps platform. And don't worry, every videos that I probably learn will be coming in the form of YouTube channel. But in this video, if you are also really interested to understand about generative AI, I've created an amazing roadmap to learn generative AI in 2024. And this will be specifically for two kinds of roles, which I'm actually going to discuss. And this roadmap, trust me, it has some prerequisites. I'm also going to provide you some videos over here, because if you just cover those prerequisites, that will be more than sufficient to start with generative AI. Yeah. And this is for all those people who are really interested to work in the data field, right? Data analytics field. If you're a developer, if you probably want to work into the generative AI, I think you don't even require this prerequisite. And I'll also call out that specific information over here in my GitHub. Once I probably show you the specific roadmap. So let me go ahead and let me share my screen. So this is the roadmap to learn generative AI. So here you can probably see everything is there. I've provided videos link, I have everything, the prerequisites that is actually required. Everything is mentioned over here. And please make sure that you fork this repository, keep a star on it, because 2024, I am going to really create a lot many things over here. It'll be quite amazing, right? Many, many things will be coming with respect to projects, with respect to frameworks, with respect to what are things I'm going to specifically cover in Lanch in everything, right? So let's start and let's understand this particular roadmap. Before you go ahead, please make sure that you hit like for this particular video will target at 2000 likes at least, you know, because this will be super beneficial because here you're going to get all the videos, all the materials, everything in front of you with respect to the prerequisites. Now I will talk about two different profiles over here. One profile is that if you want to get into the data analytics industry, and let's say you want to probably start if you're starting from scratch, okay, starting from scratch, or from past two years, you're also already in the data analytics field, you're learning about data science, what kind of upgradation you can basically do. The second type of people will be core developers, right? So in my company also, we have used generative AI, we are creating support systems, we are creating assignment, Q&A systems, many more things are there. Right now those developers are specifically creating and they don't have need to have all the knowledge with respect to some kind of prerequisites as such directly they can start with generative AI. So I will be talking about both of them step by step will try to understand. So the roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language. I will again prefer Python programming language because trust me any LLM models that is probably coming from hugging face to open AI to Mistral everywhere Python SDK is there, right? So Python SDK with the help of Python programming language, you will be able to access those API's, you'll be able to probably work on them, you will be able to probably implement any kind of applications. And not only that, you'll also be able to deploy because they are good cloud platforms that are specifically come with respect to that. Okay, so here, Python programming language, I have given this particular link, see, I've already created Python programming languages playlist for you. You can go ahead and you can check it out. This is a basic prerequisite. Even if you know, you can just refresh your knowledge. It's just some basic knowledge that is actually required. The second thing, let's say if you have a good knowledge of Python, okay, then you can skip this. But again, if you don't have knowledge with respect to Python, the basic concept of Python programming language, you need to understand and then you can start with the second step. The second step will be to learn about the machine learning fundamentals. Okay. And again, I have given a link for this and you can learn about all these machine learning fundamentals, right? Like understanding supervised learning, supervised learning, all those concepts, different algorithms, which are available, how to build the models, how to understand the evaluation metrics, how to understand the performance metrics, everything. Then the next step, which is important, which you need to understand is NLP. Okay. And here I've also given a link, which will be very useful for you. Natural language processing fundamentals are really, really important to learn because any generative AI application that you're going to build will be using a lot of NLP algorithms. Right? So NLP is really important. Understanding how tokenization is done, how embeddings are done, right? Different kind of embedding techniques, vectorization techniques, everything is really important. The next step will be understanding deep learning fundamentals. Okay. And here, deep learning fundamentals will be the basis for your generative AI. For your generative AI applications, your deep learning will be using specifically transformers, LSTM, GRU and various other architectures, CNN. And these will be helpful for you. And again, I have provided specific link for this and these are the links which you can directly access and you can understand deep learning fundamentals. After you have these prerequisites and you have a good understanding, you can start with generative AI basics, right? Like understanding what is generative AI, what are some use cases, how exactly it is working, right? Generative AI with respect to text, generative AI with respect to images, right? Generative AI with respect to sound, music, everything, right? So this particular link will give you good understanding of what is generative AI, what are some of the applications that you can build, right? So that is really important to understand the basics of generative AI. After that, you need to understand specifically the different, different frameworks and libraries that are coming up in generative AI. Right? Like your LLM models, different kinds of models, different libraries, how you can use them. So this will be really helpful for you. The next step will be working on real-time projects and examples. Okay. And again, I've given a link for this and real-time projects will really help you to understand the practical aspect. Okay. And there are various different types of projects, right? So you will be able to implement a project and then you can learn from it. Right. So that's the reason I've given this link. So this is really helpful. And the last thing, okay. The last step will be to go ahead and create your own project, right? Once you understand all these fundamentals, try to create your own projects, right? For example, building chatbots, building question answering systems, building text summarization system, building, you know, generative AI for creating music, right? So these kinds of projects you can build, you can have a good showcase of your work. And this will really help you in your interviews, in your job interviews and even with respect to your resume. So this is how you can really learn generative AI in 2024. And please make sure that you follow all the steps. This is really helpful. And I hope that this is going to really add value to you. And once again, I'm going to mention this, please make sure you hit the like button. And this is really beneficial. Thank you. Bye bye. \"\"\"\n",
        "\n",
        "\n",
        "results = summarize_text(text)\n",
        "\n",
        "# Print the combined summary and key points\n",
        "print(\"Combined Summary:\")\n",
        "print(results['combined_summary'])\n",
        "print(\"\\nKey Points:\")\n",
        "for point in results['key_points']:\n",
        "    print(f\"- {point}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SlBNja9UGPN",
        "outputId": "06e31f31-c1e4-46ae-f27b-7ce36438689f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Summary:\n",
            "In 2023, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects. MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there.\n",
            "\n",
            "All these models are specifically coming. Now people are using this in creating amazing AI applications. And you can see there are a lot of startups from image to text, text to image. There are so many different things. I was just seeing one AI platform today, you know, it is basically called as Pickalabs. You just give a prompt and it will try to create an amazing video for you, right?\n",
            "\n",
            "The roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language. If you have a good knowledge of Python, okay, then you can skip this. But again, if you don't have knowledge with respect to Python, the basic concept of Python programming language, you need to understand.\n",
            "\n",
            "The second step will be to learn about the machine learning fundamentals. And again, I have given a link for this and you can learn about all these machine learning concepts. Then the next step, which is important, which you need to understand is NLP. And here, deep learning fundamentals will be the basis for your generative AI.\n",
            "\n",
            "And there are various different types of projects, right? So you will be able to implement a project and then you can learn from it. So this is how you can really learn generative AI in 2024. And please make sure that you follow all the steps. This is really helpful.\n",
            "\n",
            "Key Points:\n",
            "- So this is how you can really learn generative AI in 2024.\n",
            "- And again, I have given a link for this and you can learn about all these machine learning concepts.\n",
            "- So you will be able to implement a project and then you can learn from it.\n",
            "- MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there.\n",
            "- The roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install summa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eFVIRZ_Zqck",
        "outputId": "4e50b90e-dc49-4852-904f-dd14cd4c807b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting summa\n",
            "  Downloading summa-1.2.0.tar.gz (54 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from summa) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy>=0.19->summa) (1.26.4)\n",
            "Building wheels for collected packages: summa\n",
            "  Building wheel for summa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for summa: filename=summa-1.2.0-py3-none-any.whl size=54389 sha256=c18e95856226ffe6dfbcf6311205e86b55dd63f7678595ebea053a61053784ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/ca/c5/4958614cfba88ed6ceb7cb5a849f9f89f9ac49971616bc919f\n",
            "Successfully built summa\n",
            "Installing collected packages: summa\n",
            "Successfully installed summa-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#text rank algo  for key text extraction\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from summa import summarizer\n",
        "import numpy as np\n",
        "\n",
        "# Load BART model and tokenizer\n",
        "model_name_bart = 'facebook/bart-large-cnn'\n",
        "tokenizer_bart = BartTokenizer.from_pretrained(model_name_bart)\n",
        "model_bart = BartForConditionalGeneration.from_pretrained(model_name_bart)\n",
        "\n",
        "def chunk_text(text, max_tokens=512):\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    current_length = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = tokenizer_bart.encode(sentence, add_special_tokens=False)\n",
        "        if current_length + len(tokens) < max_tokens:\n",
        "            current_chunk += \" \" + sentence\n",
        "            current_length += len(tokens)\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence\n",
        "            current_length = len(tokens)\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def summarize_chunk(chunk):\n",
        "    inputs = tokenizer_bart.encode(chunk, return_tensors='pt', max_length=1024, truncation=True)\n",
        "    summary_ids = model_bart.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = tokenizer_bart.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "def extract_key_points(text):\n",
        "    # Use the TextRank algorithm to extract key phrases\n",
        "    key_points = summarizer.summarize(text, ratio=0.1)  # Adjust ratio as needed to get the number of key points\n",
        "\n",
        "    # Tokenize the key points\n",
        "    key_points_sentences = sent_tokenize(key_points)\n",
        "\n",
        "    return key_points_sentences\n",
        "\n",
        "def summarize_text(text):\n",
        "    chunks = chunk_text(text)\n",
        "    summarized_chunks = [summarize_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine summaries as paragraphs\n",
        "    combined_summary = \"\\n\\n\".join(summarized_chunks)\n",
        "\n",
        "    # Extract key points from the combined summary\n",
        "    key_points = extract_key_points(combined_summary)\n",
        "\n",
        "    return {\n",
        "        'combined_summary': combined_summary,\n",
        "        'key_points': key_points\n",
        "    }\n",
        "\n",
        "# Example text\n",
        "text = \"\"\"Hello all, my name is Krushnayak and welcome to my YouTube channel. So guys before the start of every new year, I usually plan that what all skill sets I really need to add in my bucket list so that I'll be able to teach you all. I will be also able to show you that how specifically it is used in industries. In 2023, you know, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects. I have covered a lot many MLops platform tools, you know, and I've shown each and everything, which was really beneficial for many people out there who really want to make successful career transition into the data science industry. And MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there. So many tools in generative AI have actually come frameworks, libraries and many more things. So MLops will still be there in 2024. But my main aim in 2023 was to understand all about different MLops platform and try to create videos, try to upgrade myself with respect to all those skill sets and provide those videos to you. This was very beneficial. Many people were able to make successful career transition. Now in 2024, I'm also going to focus. See in 2023 also from past three to four months, I'm really much focused in generative AI solving amazing use cases, trying to see multiple frameworks, trying to see multiple LLM models, how you can fine tune it, how you can probably use it in business use cases. And based on that, I'm also creating projects. But majorly in 2024, right, the weightage between MLops and generative AI, I will try to put my most of the weightage in understanding different, different frameworks, cloud platforms, techniques in business use cases in the field of generative AI. So in this video, like if you are also interested and obviously you can see the growth in generative area, how it is happening every other day, some new things are actually coming, right? Let it be models, let it be LLM models, the recent launch of Google Gemini. I know that Gemini did not provide you the right kind of demo video. But other than that, you have Mistral 7B, you have OpenAI, GPD for turbo, right? All these models are specifically coming. Now people are using this in creating amazing AI applications. And you can see there are a lot of startups from image to text, text to image. There are so many different things. I was just seeing one AI platform today, you know, it is basically called as Pickalabs. You just give a prompt and it will try to create an amazing video for you, right? And just imagine you don't even require a video editing any person over there, right? And this is super easy, right? When you probably see this kind of application. So 2024, I'm going to completely focus most of my, if I say 100% from 100%, I'm going to focus 60 to 70% in generative AI and 30% with respect to MLOps platform. And don't worry, every videos that I probably learn will be coming in the form of YouTube channel. But in this video, if you are also really interested to understand about generative AI, I've created an amazing roadmap to learn generative AI in 2024. And this will be specifically for two kinds of roles, which I'm actually going to discuss. And this roadmap, trust me, it has some prerequisites. I'm also going to provide you some videos over here, because if you just cover those prerequisites, that will be more than sufficient to start with generative AI. Yeah. And this is for all those people who are really interested to work in the data field, right? Data analytics field. If you're a developer, if you probably want to work into the generative AI, I think you don't even require this prerequisite. And I'll also call out that specific information over here in my GitHub. Once I probably show you the specific roadmap. So let me go ahead and let me share my screen. So this is the roadmap to learn generative AI. So here you can probably see everything is there. I've provided videos link, I have everything, the prerequisites that is actually required. Everything is mentioned over here. And please make sure that you fork this repository, keep a star on it, because 2024, I am going to really create a lot many things over here. It'll be quite amazing, right? Many, many things will be coming with respect to projects, with respect to frameworks, with respect to what are things I'm going to specifically cover in Lanch in everything, right? So let's start and let's understand this particular roadmap. Before you go ahead, please make sure that you hit like for this particular video will target at 2000 likes at least, you know, because this will be super beneficial because here you're going to get all the videos, all the materials, everything in front of you with respect to the prerequisites. Now I will talk about two different profiles over here. One profile is that if you want to get into the data analytics industry, and let's say you want to probably start if you're starting from scratch, okay, starting from scratch, or from past two years, you're also already in the data analytics field, you're learning about data science, what kind of upgradation you can basically do. The second type of people will be core developers, right? So in my company also, we have used generative AI, we are creating support systems, we are creating assignment, Q&A systems, many more things are there. Right now those developers are specifically creating and they don't have need to have all the knowledge with respect to some kind of prerequisites as such directly they can start with generative AI. So I will be talking about both of them step by step will try to understand. So the roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language. I will again prefer Python programming language because trust me any LLM models that is probably coming from hugging face to open AI to Mistral everywhere Python SDK is there, right? So Python SDK with the help of Python programming language, you will be able to access those API's, you'll be able to probably work on them, you will be able to probably implement any kind of applications. And not only that, you'll also be able to deploy because they are good cloud platforms that are specifically come with respect to that. Okay, so here, Python programming language, I have given this particular link, see, I've already created Python programming languages playlist for you. You can go ahead and you can check it out. This is a basic prerequisite. Even if you know, you can just refresh your knowledge. It's just some basic knowledge that is actually required. The second thing, let's say if you have a good knowledge of Python, okay, then you can skip this. But again, if you don't have knowledge with respect to Python, the basic concept of Python programming language, you need to understand and then you can start with the second step. The second step will be to learn about the machine learning fundamentals. Okay. And again, I have given a link for this and you can learn about all these machine learning fundamentals, right? Like understanding supervised learning, supervised learning, all those concepts, different algorithms, which are available, how to build the models, how to understand the evaluation metrics, how to understand the performance metrics, everything. Then the next step, which is important, which you need to understand is NLP. Okay. And here I've also given a link, which will be very useful for you. Natural language processing fundamentals are really, really important to learn because any generative AI application that you're going to build will be using a lot of NLP algorithms. Right? So NLP is really important. Understanding how tokenization is done, how embeddings are done, right? Different kind of embedding techniques, vectorization techniques, everything is really important. The next step will be understanding deep learning fundamentals. Okay. And here, deep learning fundamentals will be the basis for your generative AI. For your generative AI applications, your deep learning will be using specifically transformers, LSTM, GRU and various other architectures, CNN. And these will be helpful for you. And again, I have provided specific link for this and these are the links which you can directly access and you can understand deep learning fundamentals. After you have these prerequisites and you have a good understanding, you can start with generative AI basics, right? Like understanding what is generative AI, what are some use cases, how exactly it is working, right? Generative AI with respect to text, generative AI with respect to images, right? Generative AI with respect to sound, music, everything, right? So this particular link will give you good understanding of what is generative AI, what are some of the applications that you can build, right? So that is really important to understand the basics of generative AI. After that, you need to understand specifically the different, different frameworks and libraries that are coming up in generative AI. Right? Like your LLM models, different kinds of models, different libraries, how you can use them. So this will be really helpful for you. The next step will be working on real-time projects and examples. Okay. And again, I've given a link for this and real-time projects will really help you to understand the practical aspect. Okay. And there are various different types of projects, right? So you will be able to implement a project and then you can learn from it. Right. So that's the reason I've given this link. So this is really helpful. And the last thing, okay. The last step will be to go ahead and create your own project, right? Once you understand all these fundamentals, try to create your own projects, right? For example, building chatbots, building question answering systems, building text summarization system, building, you know, generative AI for creating music, right? So these kinds of projects you can build, you can have a good showcase of your work. And this will really help you in your interviews, in your job interviews and even with respect to your resume. So this is how you can really learn generative AI in 2024. And please make sure that you follow all the steps. This is really helpful. And I hope that this is going to really add value to you. And once again, I'm going to mention this, please make sure you hit the like button. And this is really beneficial. Thank you. Bye bye. \"\"\"\n",
        "\n",
        "\n",
        "results = summarize_text(text)\n",
        "\n",
        "# Print the combined summary and key points\n",
        "print(\"Combined Summary:\")\n",
        "print(results['combined_summary'])\n",
        "print(\"\\nKey Points:\")\n",
        "for point in results['key_points']:\n",
        "    print(f\"- {point}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X4_U5hWUziZ",
        "outputId": "88346161-c7ab-4882-ff41-bb77661c7599"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Summary:\n",
            "In 2023, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects. MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there.\n",
            "\n",
            "All these models are specifically coming. Now people are using this in creating amazing AI applications. And you can see there are a lot of startups from image to text, text to image. There are so many different things. I was just seeing one AI platform today, you know, it is basically called as Pickalabs. You just give a prompt and it will try to create an amazing video for you, right?\n",
            "\n",
            "The roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language. If you have a good knowledge of Python, okay, then you can skip this. But again, if you don't have knowledge with respect to Python, the basic concept of Python programming language, you need to understand.\n",
            "\n",
            "The second step will be to learn about the machine learning fundamentals. And again, I have given a link for this and you can learn about all these machine learning concepts. Then the next step, which is important, which you need to understand is NLP. And here, deep learning fundamentals will be the basis for your generative AI.\n",
            "\n",
            "And there are various different types of projects, right? So you will be able to implement a project and then you can learn from it. So this is how you can really learn generative AI in 2024. And please make sure that you follow all the steps. This is really helpful.\n",
            "\n",
            "Key Points:\n",
            "- MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there.\n",
            "- So this is how you can really learn generative AI in 2024.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rake-nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeLIq4nwZ0nb",
        "outputId": "3412600f-d7ec-4c51-f7f2-9cb4daa8be63"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rake-nltk\n",
            "  Downloading rake_nltk-1.0.6-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /usr/local/lib/python3.10/dist-packages (from rake-nltk) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (4.66.5)\n",
            "Downloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
            "Installing collected packages: rake-nltk\n",
            "Successfully installed rake-nltk-1.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install rake-nltk\n",
        "#uing rake for text extraction\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from rake_nltk import Rake\n",
        "\n",
        "# Load the BART model and tokenizer\n",
        "model_name = 'facebook/bart-large-cnn'\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "def chunk_text(text, max_tokens=512):\n",
        "    sentences = sent_tokenize(text)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "    current_length = 0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = tokenizer.encode(sentence, add_special_tokens=False)\n",
        "        if current_length + len(tokens) < max_tokens:\n",
        "            current_chunk += \" \" + sentence\n",
        "            current_length += len(tokens)\n",
        "        else:\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence\n",
        "            current_length = len(tokens)\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def summarize_chunk(chunk):\n",
        "    inputs = tokenizer.encode(chunk, return_tensors='pt', max_length=1024, truncation=True)\n",
        "    summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "def extract_key_points(text):\n",
        "    r = Rake()  # Initialize RAKE\n",
        "    r.extract_keywords_from_text(text)  # Extract keywords\n",
        "    key_points = r.get_ranked_phrases()  # Get ranked phrases\n",
        "    return key_points\n",
        "\n",
        "def summarize_text(text):\n",
        "    chunks = chunk_text(text)\n",
        "    summarized_chunks = [summarize_chunk(chunk) for chunk in chunks]\n",
        "\n",
        "    # Combine summaries as paragraphs\n",
        "    combined_summary = \"\\n\\n\".join(summarized_chunks)\n",
        "\n",
        "    # Extract key points from the combined summary\n",
        "    key_points = extract_key_points(combined_summary)\n",
        "\n",
        "    return {\n",
        "        'combined_summary': combined_summary,\n",
        "        'key_points': key_points\n",
        "    }\n",
        "\n",
        "# Example text\n",
        "text = \"\"\"Hello all, my name is Krushnayak and welcome to my YouTube channel. So guys before the start of every new year, I usually plan that what all skill sets I really need to add in my bucket list so that I'll be able to teach you all. I will be also able to show you that how specifically it is used in industries. In 2023, you know, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects. I have covered a lot many MLops platform tools, you know, and I've shown each and everything, which was really beneficial for many people out there who really want to make successful career transition into the data science industry. And MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there. So many tools in generative AI have actually come frameworks, libraries and many more things. So MLops will still be there in 2024. But my main aim in 2023 was to understand all about different MLops platform and try to create videos, try to upgrade myself with respect to all those skill sets and provide those videos to you. This was very beneficial. Many people were able to make successful career transition. Now in 2024, I'm also going to focus. See in 2023 also from past three to four months, I'm really much focused in generative AI solving amazing use cases, trying to see multiple frameworks, trying to see multiple LLM models, how you can fine tune it, how you can probably use it in business use cases. And based on that, I'm also creating projects. But majorly in 2024, right, the weightage between MLops and generative AI, I will try to put my most of the weightage in understanding different, different frameworks, cloud platforms, techniques in business use cases in the field of generative AI. So in this video, like if you are also interested and obviously you can see the growth in generative area, how it is happening every other day, some new things are actually coming, right? Let it be models, let it be LLM models, the recent launch of Google Gemini. I know that Gemini did not provide you the right kind of demo video. But other than that, you have Mistral 7B, you have OpenAI, GPD for turbo, right? All these models are specifically coming. Now people are using this in creating amazing AI applications. And you can see there are a lot of startups from image to text, text to image. There are so many different things. I was just seeing one AI platform today, you know, it is basically called as Pickalabs. You just give a prompt and it will try to create an amazing video for you, right? And just imagine you don't even require a video editing any person over there, right? And this is super easy, right? When you probably see this kind of application. So 2024, I'm going to completely focus most of my, if I say 100% from 100%, I'm going to focus 60 to 70% in generative AI and 30% with respect to MLOps platform. And don't worry, every videos that I probably learn will be coming in the form of YouTube channel. But in this video, if you are also really interested to understand about generative AI, I've created an amazing roadmap to learn generative AI in 2024. And this will be specifically for two kinds of roles, which I'm actually going to discuss. And this roadmap, trust me, it has some prerequisites. I'm also going to provide you some videos over here, because if you just cover those prerequisites, that will be more than sufficient to start with generative AI. Yeah. And this is for all those people who are really interested to work in the data field, right? Data analytics field. If you're a developer, if you probably want to work into the generative AI, I think you don't even require this prerequisite. And I'll also call out that specific information over here in my GitHub. Once I probably show you the specific roadmap. So let me go ahead and let me share my screen. So this is the roadmap to learn generative AI. So here you can probably see everything is there. I've provided videos link, I have everything, the prerequisites that is actually required. Everything is mentioned over here. And please make sure that you fork this repository, keep a star on it, because 2024, I am going to really create a lot many things over here. It'll be quite amazing, right? Many, many things will be coming with respect to projects, with respect to frameworks, with respect to what are things I'm going to specifically cover in Lanch in everything, right? So let's start and let's understand this particular roadmap. Before you go ahead, please make sure that you hit like for this particular video will target at 2000 likes at least, you know, because this will be super beneficial because here you're going to get all the videos, all the materials, everything in front of you with respect to the prerequisites. Now I will talk about two different profiles over here. One profile is that if you want to get into the data analytics industry, and let's say you want to probably start if you're starting from scratch, okay, starting from scratch, or from past two years, you're also already in the data analytics field, you're learning about data science, what kind of upgradation you can basically do. The second type of people will be core developers, right? So in my company also, we have used generative AI, we are creating support systems, we are creating assignment, Q&A systems, many more things are there. Right now those developers are specifically creating and they don't have need to have all the knowledge with respect to some kind of prerequisites as such directly they can start with generative AI. So I will be talking about both of them step by step will try to understand. So the roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language. I will again prefer Python programming language because trust me any LLM models that is probably coming from hugging face to open AI to Mistral everywhere Python SDK is there, right? So Python SDK with the help of Python programming language, you will be able to access those API's, you'll be able to probably work on them, you will be able to probably implement any kind of applications. And not only that, you'll also be able to deploy because they are good cloud platforms that are specifically come with respect to that. Okay, so here, Python programming language, I have given this particular link, see, I've already created Python programming languages playlist for you. You can go ahead and you can check it out. This is a basic prerequisite. Even if you know, you can just refresh your knowledge. It's just some basic knowledge that is actually required. The second thing, let's say if you have a good knowledge of Python, okay, then you can skip this. But again, if you don't have knowledge with respect to Python, the basic concept of Python programming language, you need to understand and then you can start with the second step. The second step will be to learn about the machine learning fundamentals. Okay. And again, I have given a link for this and you can learn about all these machine learning fundamentals, right? Like understanding supervised learning, supervised learning, all those concepts, different algorithms, which are available, how to build the models, how to understand the evaluation metrics, how to understand the performance metrics, everything. Then the next step, which is important, which you need to understand is NLP. Okay. And here I've also given a link, which will be very useful for you. Natural language processing fundamentals are really, really important to learn because any generative AI application that you're going to build will be using a lot of NLP algorithms. Right? So NLP is really important. Understanding how tokenization is done, how embeddings are done, right? Different kind of embedding techniques, vectorization techniques, everything is really important. The next step will be understanding deep learning fundamentals. Okay. And here, deep learning fundamentals will be the basis for your generative AI. For your generative AI applications, your deep learning will be using specifically transformers, LSTM, GRU and various other architectures, CNN. And these will be helpful for you. And again, I have provided specific link for this and these are the links which you can directly access and you can understand deep learning fundamentals. After you have these prerequisites and you have a good understanding, you can start with generative AI basics, right? Like understanding what is generative AI, what are some use cases, how exactly it is working, right? Generative AI with respect to text, generative AI with respect to images, right? Generative AI with respect to sound, music, everything, right? So this particular link will give you good understanding of what is generative AI, what are some of the applications that you can build, right? So that is really important to understand the basics of generative AI. After that, you need to understand specifically the different, different frameworks and libraries that are coming up in generative AI. Right? Like your LLM models, different kinds of models, different libraries, how you can use them. So this will be really helpful for you. The next step will be working on real-time projects and examples. Okay. And again, I've given a link for this and real-time projects will really help you to understand the practical aspect. Okay. And there are various different types of projects, right? So you will be able to implement a project and then you can learn from it. Right. So that's the reason I've given this link. So this is really helpful. And the last thing, okay. The last step will be to go ahead and create your own project, right? Once you understand all these fundamentals, try to create your own projects, right? For example, building chatbots, building question answering systems, building text summarization system, building, you know, generative AI for creating music, right? So these kinds of projects you can build, you can have a good showcase of your work. And this will really help you in your interviews, in your job interviews and even with respect to your resume. So this is how you can really learn generative AI in 2024. And please make sure that you follow all the steps. This is really helpful. And I hope that this is going to really add value to you. And once again, I'm going to mention this, please make sure you hit the like button. And this is really beneficial. Thank you. Bye bye. \"\"\"\n",
        "\n",
        "# Summarize the text and extract key points\n",
        "results = summarize_text(text)\n",
        "\n",
        "# Print the combined summary and key points\n",
        "print(\"Combined Summary:\")\n",
        "print(results['combined_summary'])\n",
        "print(\"\\nKey Points:\")\n",
        "for point in results['key_points']:\n",
        "    print(f\"- {point}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NX-nU5_pa1CE",
        "outputId": "9a6f8b85-f0c7-4bc0-e68f-76fc2516c2b8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Summary:\n",
            "In 2023, I had targeted various MLops platform and if you probably see my videos in my YouTube channel, I've covered a lot of end to end projects. MLops, I think in 2024 also it will play a very important role since right now LLM applications are basically coming up, you know, generative AI is there.\n",
            "\n",
            "All these models are specifically coming. Now people are using this in creating amazing AI applications. And you can see there are a lot of startups from image to text, text to image. There are so many different things. I was just seeing one AI platform today, you know, it is basically called as Pickalabs. You just give a prompt and it will try to create an amazing video for you, right?\n",
            "\n",
            "The roadmap to learn about generative AI in 2024 is that first of all, you start with one programming language. If you have a good knowledge of Python, okay, then you can skip this. But again, if you don't have knowledge with respect to Python, the basic concept of Python programming language, you need to understand.\n",
            "\n",
            "The second step will be to learn about the machine learning fundamentals. And again, I have given a link for this and you can learn about all these machine learning concepts. Then the next step, which is important, which you need to understand is NLP. And here, deep learning fundamentals will be the basis for your generative AI.\n",
            "\n",
            "And there are various different types of projects, right? So you will be able to implement a project and then you can learn from it. So this is how you can really learn generative AI in 2024. And please make sure that you follow all the steps. This is really helpful.\n",
            "\n",
            "Key Points:\n",
            "- seeing one ai platform today\n",
            "- targeted various mlops platform\n",
            "- creating amazing ai applications\n",
            "- important role since right\n",
            "- really learn generative ai\n",
            "- one programming language\n",
            "- various different types\n",
            "- please make sure\n",
            "- many different things\n",
            "- machine learning fundamentals\n",
            "- machine learning concepts\n",
            "- deep learning fundamentals\n",
            "- python programming language\n",
            "- generative ai\n",
            "- generative ai\n",
            "- generative ai\n",
            "- really helpful\n",
            "- llm applications\n",
            "- amazing video\n",
            "- youtube channel\n",
            "- specifically coming\n",
            "- second step\n",
            "- next step\n",
            "- basically coming\n",
            "- basically called\n",
            "- basic concept\n",
            "- probably see\n",
            "- good knowledge\n",
            "- 2024 also\n",
            "- end projects\n",
            "- mlops\n",
            "- important\n",
            "- right\n",
            "- right\n",
            "- python\n",
            "- python\n",
            "- learn\n",
            "- learn\n",
            "- learn\n",
            "- learn\n",
            "- see\n",
            "- projects\n",
            "- knowledge\n",
            "- end\n",
            "- 2024\n",
            "- 2024\n",
            "- videos\n",
            "- using\n",
            "- understand\n",
            "- understand\n",
            "- try\n",
            "- think\n",
            "- text\n",
            "- text\n",
            "- steps\n",
            "- startups\n",
            "- start\n",
            "- skip\n",
            "- roadmap\n",
            "- respect\n",
            "- prompt\n",
            "- project\n",
            "- play\n",
            "- pickalabs\n",
            "- people\n",
            "- okay\n",
            "- nlp\n",
            "- need\n",
            "- need\n",
            "- models\n",
            "- lot\n",
            "- lot\n",
            "- link\n",
            "- know\n",
            "- know\n",
            "- implement\n",
            "- image\n",
            "- image\n",
            "- given\n",
            "- give\n",
            "- follow\n",
            "- first\n",
            "- create\n",
            "- covered\n",
            "- basis\n",
            "- able\n",
            "- 2023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9YqRzeobEcI",
        "outputId": "1f113791-9735-4839-b8a9-4bcb8368632e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v-2ovvSycW9t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}